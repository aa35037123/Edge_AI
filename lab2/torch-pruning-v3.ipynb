{"cells":[{"cell_type":"markdown","metadata":{"id":"RdC9V9xB10Gt"},"source":["# **Template for Torch-Pruning**\n","\n","This template is just built for your convinience.\n","\n","You are not required to follow the steps and method given below."]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T09:19:10.718584Z","iopub.status.busy":"2024-03-29T09:19:10.718213Z"},"id":"7jfw5rNimfwu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch_pruning in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (1.3.7)\n","Requirement already satisfied: torch in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch_pruning) (2.2.1)\n","Requirement already satisfied: numpy in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch_pruning) (1.26.4)\n","Requirement already satisfied: filelock in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (4.9.0)\n","Requirement already satisfied: sympy in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (1.12)\n","Requirement already satisfied: networkx in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.1)\n","Requirement already satisfied: jinja2 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.1.3)\n","Requirement already satisfied: fsspec in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (2024.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from jinja2->torch->torch_pruning) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from sympy->torch->torch_pruning) (1.3.0)\n","Requirement already satisfied: torchprofile in /home/aa35037123/.local/lib/python3.10/site-packages (0.0.4)\n","Requirement already satisfied: numpy>=1.14 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torchprofile) (1.26.4)\n","Requirement already satisfied: torch>=1.4 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torchprofile) (2.2.1)\n","Requirement already satisfied: torchvision>=0.4 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torchprofile) (0.17.1)\n","Requirement already satisfied: filelock in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (4.9.0)\n","Requirement already satisfied: sympy in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (1.12)\n","Requirement already satisfied: networkx in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1)\n","Requirement already satisfied: jinja2 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1.3)\n","Requirement already satisfied: fsspec in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2024.3.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (10.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n"]}],"source":["!pip install --upgrade torch_pruning\n","!pip install torchprofile\n","# !pip install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"-LiF8Vrqm2FU","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.models import mobilenet_v2\n","import torch_pruning as tp\n","from functools import partial\n","import copy\n","import math\n","import random\n","import time\n","from collections import OrderedDict, defaultdict\n","from typing import Union, List\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from torch import nn\n","from torch.optim import *\n","from torch.optim.lr_scheduler import *\n","from torch.utils.data import DataLoader\n","from torchprofile import profile_macs\n","from torchvision.datasets import *\n","from torchvision.transforms import *\n","from tqdm.auto import tqdm\n","import torch.nn.functional as F\n","from torchprofile import profile_macs\n","import os"]},{"cell_type":"markdown","metadata":{"id":"dQ411pYQhkw4"},"source":["## A Minimal Example   \n","In this section, you will perform channel pruning using the library [Torch-Pruning](https://github.com/VainF/Torch-Pruning).  \n","\n","The puuner in Torch-Pruning has three main functions: sparse training (optional), importance estimation, and parameter removal.  \n","Torch-pruning offers two core features to support this process:\n","\n","tp.importance(): This criteria is utilized to measure the importance of weights.  \n","\n","tp.pruner(): This is a pruner used for the actual pruning of the parameters.  \n","\n","For detailed information on this process, please refer to this [tutorial](https://github.com/VainF/Torch-Pruning/wiki/4.-High%E2%80%90level-Pruners/). Additionally, a more practical example is available in [here](https://github.com/VainF/Torch-Pruning/blob/master/benchmarks/main.py)."]},{"cell_type":"markdown","metadata":{"id":"s9e8CpBhmph9"},"source":["### 1. Load model\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"umaWm4eYms6G","trusted":true},"outputs":[],"source":["model = torch.load('./mobilenetv2_0.963.pth', map_location=\"cpu\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"mSe6NDqqm_qN"},"source":["### 2. Prepare a pruner\n","By default, Torch-Pruning will automatically prune the last non-singleton dim of these parameters. If you want to customize this behaviour, please provide an `unwrapped_parameters` list as the following example."]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transforms = {\n","    \"train\": Compose([\n","      Resize((224, 224)),\n","      ToTensor(),\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ]),\n","    \"test\": Compose([\n","      Resize((224, 224)),\n","      ToTensor(),\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","dataset = {}\n","for split in [\"train\", \"test\"]:\n","  dataset[split] = CIFAR10(\n","    root=\"data/cifar10\",\n","    train=(split == \"train\"),\n","    download=True,\n","    transform=transforms[split],\n","  )\n","\n","# You can apply your own batch_size\n","dataloader = {}\n","for split in ['train', 'test']:\n","  dataloader[split] = DataLoader(\n","    dataset[split],\n","    batch_size=10,\n","    shuffle=(split == 'train'),\n","    num_workers=0,\n","    pin_memory=True,\n","    drop_last=True\n","  )"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["def progressive_pruning(pruner, model, speed_up, example_inputs, train_loader=None):\n","    model.eval()\n","    base_ops, _ = tp.utils.count_ops_and_params(model, example_inputs=example_inputs)\n","    current_speed_up = 1\n","    while current_speed_up < speed_up:\n","#         model.zero_grad()\n","#         imp=pruner.importance\n","#         imp._prepare_model(model, pruner)\n","#         for k, (imgs, lbls) in enumerate(train_loader):\n","#             if k>=10: break\n","#             imgs = imgs.cuda()\n","#             lbls = lbls.cuda()\n","#             output = model(imgs)\n","# #             sampled_y = torch.multinomial(torch.nn.functional.softmax(output.cpu().data, dim=1),\n","# #                                               1).squeeze().cuda()\n","# #             loss_sample = F.cross_entropy(output, sampled_y)\n","#             loss_sample = nn.CrossEntropyLoss()(output, lbls)\n","#             loss_sample.backward()\n","#             imp.step()\n","        pruner.step()\n","        pruned_ops, _ = tp.utils.count_ops_and_params(model, example_inputs=example_inputs)\n","        current_speed_up = float(base_ops) / pruned_ops\n","        if pruner.current_step == pruner.iterative_steps:\n","            break\n","    return current_speed_up"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["output_dir = \"./pruning_output\"\n","def eval(model, test_loader, device=None, verbose=True):\n","\n","    num_samples = 0\n","    num_correct = 0\n","    \n","    model.to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, targets in tqdm(test_loader, desc=\"eval\", leave=False,\n","                                    disable=not verbose):\n","            # Move the data from CPU to GPU\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","\n","            # Inference\n","            outputs = model(inputs)\n","\n","            # Convert logits to class indices\n","            outputs = outputs.argmax(dim=1)\n","\n","            # Update metrics\n","            num_samples += targets.size(0)\n","            num_correct += (outputs == targets).sum()\n","\n","    return (num_correct / num_samples * 100).item()\n","\n","def train_model(\n","    model,\n","    train_loader,\n","    test_loader,\n","    epochs,\n","    lr,\n","    lr_decay_milestones,\n","    lr_decay_gamma = 0.7,\n","    save_as=None,\n","    \n","    # For pruning\n","    weight_decay=1e-4,\n","    save_state_dict_only=True,\n","    pruner=None,\n","    device=None,\n","    verbose=False\n","):\n","    if device is None:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n","    # milestones = [int(ms) for ms in lr_decay_milestones.split(\",\")]\n","    # scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","    #     optimizer, milestones=milestones, gamma=lr_decay_gamma\n","    # )\n","    if pruner is not None:\n","        pruner.update_regularizer()\n","    model.to(device)\n","    best_acc = -1\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","\n","        for i, (inputs, targets) in enumerate(tqdm(train_loader, desc='train', leave=False)):\n","            # Move the data from CPU to GPU\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","            # Reset the gradients (from the last iteration)\n","            optimizer.zero_grad()\n","\n","            # Forward inference\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            # Backward propagation\n","            loss.backward()\n","\n","            if pruner is not None:\n","                pruner.regularize(model) # for sparsity learning\n","\n","            # Update optimizer and LR scheduler\n","            optimizer.step()\n","            if i % 10 == 0 and verbose:\n","                print(\n","                    \"Epoch {:d}/{:d}, iter {:d}/{:d}, loss={:.4f}, lr={:.4f}\".format(\n","                        epoch,\n","                        epochs,\n","                        i,\n","                        len(train_loader),\n","                        loss.item(),\n","                        optimizer.param_groups[0][\"lr\"],\n","                    )\n","                )\n","\n","        if pruner is not None and isinstance(pruner, tp.pruner.GrowingRegPruner):\n","            pruner.update_reg() # increase the strength of regularization\n","            #print(pruner.group_reg[pruner._groups[0]])\n","        \n","        model.eval()\n","        acc = eval(model, test_loader, device=device)\n","        print(\n","            \"Epoch {:d}/{:d}, Acc={:.4f}, lr={:.4f}\".format(\n","                epoch, epochs, acc, optimizer.param_groups[0][\"lr\"]\n","            )\n","        )\n","        if best_acc < acc:\n","            os.makedirs(output_dir, exist_ok=True)\n","            \n","            if save_as is None:\n","                save_as = os.path.join(output_dir, \"{}_{}_{}.pth\".format('CIFAR10', 'mobilenet', 'group_norm'))\n","\n","            if save_state_dict_only:\n","                torch.save(model.state_dict(), save_as)\n","            else:\n","                torch.save(model, save_as)\n","            best_acc = acc\n","        scheduler.step()\n","    print(\"Best Acc=%.4f\" % (best_acc))"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"up4Y3mqCnEIR","trusted":true},"outputs":[],"source":["NUM_CLASSES = 10\n","# Importance criterion\n","# imp = tp.pruner.importance.OBDCImportance(group_reduction='mean', num_classes=NUM_CLASSES)\n","# pruner_entry = partial(tp.pruner.MagnitudePruner, global_pruning=True)\n","\n","# imp = tp.importance.GroupNormImportance(p=2) # or GroupTaylorImportance(), GroupHessianImportance(), etc.\n","# pruner_entry = partial(tp.pruner.GroupNormPruner, global_pruning=False)\n","\n","imp = tp.importance.GroupNormImportance(p=2, normalizer='max') # normalized by the maximum score for CIFAR\n","pruner_entry = partial(tp.pruner.GroupNormPruner, reg=5e-4, global_pruning=True)\n","\n","# Initialize a pruner with the model and the importance criterion\n","example_inputs = torch.randn(1, 3, 224, 224).to(device)\n","\n","unwrapped_parameters = []\n","ignored_layers = []\n","pruning_ratio_dict = {}\n","for m in model.modules():\n","  if isinstance(m, torch.nn.Linear) and m.out_features == NUM_CLASSES: # ignore the classifier\n","    ignored_layers.append(m)\n","  elif isinstance(m, torch.nn.modules.conv._ConvNd) and m.out_channels == NUM_CLASSES:\n","            ignored_layers.append(m)\n","\n","pruner = pruner_entry(\n","        model,\n","        example_inputs,\n","        importance=imp,\n","        iterative_steps=500,\n","        pruning_ratio=0.6,\n","        pruning_ratio_dict=pruning_ratio_dict,\n","        max_pruning_ratio=0.95,\n","        ignored_layers=ignored_layers,\n","        unwrapped_parameters=unwrapped_parameters,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"d1XmDH9ToKYO"},"source":["### 3. Prune the model"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"qmklPY2goMX2","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["base acc: 96.30000305175781\n","Pruning...\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["Params: 2.24 M => 0.38 M (17.10%)\n","FLOPs: 318.97 M => 61.33 M (19.23%, 5.20X )\n","Acc: 96.3000 => 10.0000\n","The first pruned model:\n","MobileNetV2(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n","          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2d(12, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(6, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(38, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=38, bias=False)\n","          (1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(38, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(9, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=57, bias=False)\n","          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(57, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(9, 57, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(57, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=57, bias=False)\n","          (1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(57, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76, bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(76, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76, bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(76, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(12, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(76, 76, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=76, bias=False)\n","          (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(76, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(153, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(25, 153, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=153, bias=False)\n","          (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(153, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=230, bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(230, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=230, bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(230, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(38, 230, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(230, 230, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=230, bias=False)\n","          (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(230, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU6(inplace=True)\n","        )\n","        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (18): Conv2dNormActivation(\n","      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","Summary:\n","MFLOPs: \n","61.325886\n","Finetuning...\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/500, Acc=67.6800, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/500, Acc=77.5300, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/500, Acc=80.0800, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/500, Acc=81.2100, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/500, Acc=82.2300, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/500, Acc=84.0600, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/500, Acc=83.7300, lr=0.0100\n"]},{"name":"stderr","output_type":"stream","text":["                                                          \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 2. Finetuning\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinetuning...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr_decay_milestones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10, 20, 40, 60, 80, 100, 120, 140\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr_decay_gamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_as\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_state_dict_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpruner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[38], line 70\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, epochs, lr, lr_decay_milestones, lr_decay_gamma, save_as, weight_decay, save_state_dict_only, pruner, device, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Forward inference\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Backward propagation\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torchvision/models/mobilenetv2.py:174\u001b[0m, in \u001b[0;36mMobileNetV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torchvision/models/mobilenetv2.py:166\u001b[0m, in \u001b[0;36mMobileNetV2._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Cannot use \"squeeze\" as batch-size can be 1\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/lab2/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# sparsity learning\n","reg_pth = \"reg_{}_{}_{}_{}.pth\".format(\"CIFAR-10\", \"mobilenet\", \"group_sl\", \"5e-4\")\n","reg_pth = os.path.join( os.path.join(output_dir, reg_pth) )\n","print(\"Regularizing...\")\n","train_model(\n","    model,\n","    train_loader=dataloader['train'],\n","    test_loader=dataloader['test'],\n","    epochs=100,\n","    lr=0.01,\n","    lr_decay_milestones=\"40, 60\",\n","    lr_decay_gamma=0.1,\n","    pruner=pruner,\n","    save_state_dict_only=True,\n","    save_as = reg_pth,\n",")\n","print(\"Loading the sparse model from {}...\".format(reg_pth))\n","model.load_state_dict( torch.load( reg_pth, map_location=device))\n","\n","# pruning\n","target_speed_up = 7\n","# Model size before pruning\n","model.eval()\n","# first_speed_up = 4\n","base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n","base_acc = eval(model, dataloader['test'], device=device)\n","\n","print(f'base acc: {base_acc}')\n","if isinstance(imp, tp.importance.GroupTaylorImportance):\n","  # Taylor expansion requires gradients for importance estimation\n","  loss = model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n","  loss.backward() # before pruner.step()\n","\n","print(\"Pruning...\")\n","\n","progressive_pruning(pruner, model, speed_up=target_speed_up, example_inputs=example_inputs, train_loader=dataloader['train'])\n","\n","# Parameter & MACs Counter\n","pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n","pruned_acc = eval(model, dataloader['test'], device=device)\n","print(\"Params: {:.2f} M => {:.2f} M ({:.2f}%)\".format(\n","                base_nparams / 1e6, pruned_nparams / 1e6, pruned_nparams / base_nparams * 100\n","            ))\n","print(\"FLOPs: {:.2f} M => {:.2f} M ({:.2f}%, {:.2f}X )\".format(\n","                base_macs / 1e6,\n","                pruned_macs / 1e6,\n","                pruned_macs / base_macs * 100,\n","                base_macs / pruned_macs,\n","            ))\n","print(\"Acc: {:.4f} => {:.4f}\".format(base_acc, pruned_acc))\n","MFLOPs = pruned_macs/1e6\n","print(\"The first pruned model:\")\n","print(model)\n","print(\"Summary:\")\n","print(\"MFLOPs: \")\n","print(MFLOPs)\n","\n","# 2. Finetuning\n","print('Finetuning...')\n","train_model(\n","                model,\n","                train_loader=dataloader['train'],\n","                test_loader=dataloader['test'],\n","                epochs=200,\n","                lr=0.01,\n","                lr_decay_milestones=\"60, 100, 150, 180\",\n","                lr_decay_gamma=0.1,\n","                save_as=None,\n","                weight_decay=1e-4,\n","                save_state_dict_only=False,\n","                pruner=None,\n","                device=device,\n","                verbose=False\n","            )"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":17665,"sourceId":21333,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
