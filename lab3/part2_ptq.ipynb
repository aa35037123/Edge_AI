{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfRESKfRZzs3",
        "outputId": "59fcb1d4-11ac-415a-a558-7c8cc0f848b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjmY1ydrZls5",
        "outputId": "d0060f27-cfa5-4cbd-f135-c27a36e9aa1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping timm as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Collecting torchdata\n",
            "  Using cached torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Collecting timm\n",
            "  Using cached timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.0 (from torch)\n",
            "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchtext, torchdata, torchaudio, timm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 timm-0.9.16 torch-2.3.0 torchaudio-2.3.0 torchdata-0.7.1 torchtext-0.18.0 torchvision-0.18.0 triton-2.3.0\n"
          ]
        }
      ],
      "source": [
        "# install the newest version of torch, torchvision, and timm\n",
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata timm\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UVSaQdJvZiWT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch._export import capture_pre_autograd_graph\n",
        "\n",
        "from torchvision.models import mobilenet_v2\n",
        "# from torchvision.models.quantization import mobilenet_v2\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3HfU9hhrZiWU"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader,device):\n",
        "\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the test images: {accuracy}%')\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4tO3t7BZiWV",
        "outputId": "87b1cfe1-6ac2-4582-b1ae-2f53f1397e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29783563.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to match MobileNet input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,drop_last=True)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "batch_size = 16\n",
        "train_loader, test_loader = prepare_data(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vO6QisM6ZiWV"
      },
      "outputs": [],
      "source": [
        "def calibrate(model, data_loader, device):\n",
        "    # model.eval()\n",
        "    # torch.ao.quantization.move_exported_model_to_train(model)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DJyItBVEtKMp"
      },
      "outputs": [],
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN5LrZoJZiWW",
        "outputId": "fc07ff3f-57fa-4713-daa1-283885aba98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "# device = torch.device('cpu')\n",
        "weight_path = '/content/drive/MyDrive/mobilenetv2_0.963.pth'\n",
        "model = torch.load(weight_path, map_location=torch.device('cpu'))\n",
        "model.to(device)\n",
        "print(next(model.parameters()).is_cuda)\n",
        "model.eval()\n",
        "example_inputs = (torch.randn(1, 3, 224, 224).to(device),)\n",
        "exported_model = capture_pre_autograd_graph(model, example_inputs)\n",
        "# Step 2. quantization\n",
        "from torch.ao.quantization.quantize_pt2e import (\n",
        "  prepare_pt2e,\n",
        "  convert_pt2e,\n",
        ")\n",
        "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
        "  XNNPACKQuantizer,\n",
        "  get_symmetric_quantization_config,\n",
        ")\n",
        "# from torch.ao.quantization.quantizer import (\n",
        "#   XNNPACKQuantizer,\n",
        "#   get_symmetric_quantization_config,\n",
        "# )\n",
        "# backend developer will write their own Quantizer and expose methods to allow\n",
        "# users to express how they\n",
        "# want the model to be quantized\n",
        "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())\n",
        "prepared_model = prepare_pt2e(exported_model, quantizer)\n",
        "# print(prepared_model.graph)\n",
        "# calibration omitted\n",
        "calibrate(prepared_model, test_loader, device)  # run calibration on sample data\n",
        "ptq_quantized_model = convert_pt2e(prepared_model)\n",
        "# print(ptq_quantized_model)\n",
        "# we have a model with aten ops doing integer computations when possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G201Zn_kZiWW",
        "outputId": "814a9529-37f3-4841-bde5-57ec6bc15e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modle has been export!\n"
          ]
        }
      ],
      "source": [
        "# Export the model and Save ExportedProgram\n",
        "pt2e_quantized_model_file_path =  \"./mobilenet_quantized.pt\"\n",
        "# capture the model to get an ExportedProgram\n",
        "example_inputs = (next(iter(test_loader))[0].to(device),)\n",
        "torch.ao.quantization.move_exported_model_to_eval(ptq_quantized_model)\n",
        "quantized_ep = torch.export.export(ptq_quantized_model, example_inputs)\n",
        "# use torch.export.save to save an ExportedProgram\n",
        "torch.export.save(quantized_ep, pt2e_quantized_model_file_path)\n",
        "print('Modle has been export!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcQNgb08ZiWW"
      },
      "outputs": [],
      "source": [
        "loaded_quantized_ep = torch.export.load(\"/content/mobilenet_quantized.pth\")\n",
        "loaded_quantized_model = loaded_quantized_ep.module()\n",
        "acc = evaluate_model(loaded_quantized_model, test_loader, device)\n",
        "print_size_of_model(loaded_quantized_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
