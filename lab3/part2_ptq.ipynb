{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch._export import capture_pre_autograd_graph\n",
    "\n",
    "from torchvision.models import mobilenet_v2\n",
    "# from torchvision.models.quantization import mobilenet_v2\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader,device):\n",
    "\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to match MobileNet input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "batch_size = 16\n",
    "train_loader, test_loader = prepare_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(model, data_loader):\n",
    "    # model.eval()\n",
    "    torch.ao.quantization.move_exported_model_to_train(model)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    arg0, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    arg0_1 = arg0\n",
      "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(arg0_1, 1.0, 0, -128, 127, torch.int8);  arg0_1 = None\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None\n",
      "    _frozen_param0 = self._frozen_param0\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param0, 1.0, 0, -127, 127, torch.int8);  _frozen_param0 = None\n",
      "    features_0_0_weight_bias = self.features_0_0_weight_bias\n",
      "    conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_default_1, features_0_0_weight_bias, [2, 2], [1, 1]);  dequantize_per_tensor_default = dequantize_per_tensor_default_1 = features_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 1.0, 0, -128, 127, torch.int8);  conv2d = None\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None\n",
      "    hardtanh_ = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_2, 0.0, 6.0);  dequantize_per_tensor_default_2 = None\n",
      "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh_, 1.0, 0, -128, 127, torch.int8);  hardtanh_ = None\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
      "    _frozen_param1 = self._frozen_param1\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param1, 1.0, 0, -127, 127, torch.int8);  _frozen_param1 = None\n",
      "    features_1_conv_0_0_weight_bias = self.features_1_conv_0_0_weight_bias\n",
      "    conv2d_1 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor_default_4, features_1_conv_0_0_weight_bias, [1, 1], [1, 1], [1, 1], 32);  dequantize_per_tensor_default_3 = dequantize_per_tensor_default_4 = features_1_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_5 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_1, 1.0, 0, -128, 127, torch.int8);  conv2d_1 = None\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_5 = None\n",
      "    hardtanh__1 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_5, 0.0, 6.0);  dequantize_per_tensor_default_5 = None\n",
      "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__1, 1.0, 0, -128, 127, torch.int8);  hardtanh__1 = None\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_6 = None\n",
      "    _frozen_param2 = self._frozen_param2\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param2, 1.0, 0, -127, 127, torch.int8);  _frozen_param2 = None\n",
      "    features_1_conv_1_weight_bias = self.features_1_conv_1_weight_bias\n",
      "    conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_6, dequantize_per_tensor_default_7, features_1_conv_1_weight_bias);  dequantize_per_tensor_default_6 = dequantize_per_tensor_default_7 = features_1_conv_1_weight_bias = None\n",
      "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 1.0, 0, -128, 127, torch.int8);  conv2d_2 = None\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
      "    _frozen_param3 = self._frozen_param3\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param3, 1.0, 0, -127, 127, torch.int8);  _frozen_param3 = None\n",
      "    features_2_conv_0_0_weight_bias = self.features_2_conv_0_0_weight_bias\n",
      "    conv2d_3 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_8, dequantize_per_tensor_default_9, features_2_conv_0_0_weight_bias);  dequantize_per_tensor_default_8 = dequantize_per_tensor_default_9 = features_2_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_3, 1.0, 0, -128, 127, torch.int8);  conv2d_3 = None\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_10 = None\n",
      "    hardtanh__2 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_10, 0.0, 6.0);  dequantize_per_tensor_default_10 = None\n",
      "    quantize_per_tensor_default_11 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__2, 1.0, 0, -128, 127, torch.int8);  hardtanh__2 = None\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_11 = None\n",
      "    _frozen_param4 = self._frozen_param4\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param4, 1.0, 0, -127, 127, torch.int8);  _frozen_param4 = None\n",
      "    features_2_conv_1_0_weight_bias = self.features_2_conv_1_0_weight_bias\n",
      "    conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_11, dequantize_per_tensor_default_12, features_2_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 96);  dequantize_per_tensor_default_11 = dequantize_per_tensor_default_12 = features_2_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_13 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 1.0, 0, -128, 127, torch.int8);  conv2d_4 = None\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_13, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_13 = None\n",
      "    hardtanh__3 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_13, 0.0, 6.0);  dequantize_per_tensor_default_13 = None\n",
      "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__3, 1.0, 0, -128, 127, torch.int8);  hardtanh__3 = None\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
      "    _frozen_param5 = self._frozen_param5\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param5, 1.0, 0, -127, 127, torch.int8);  _frozen_param5 = None\n",
      "    features_2_conv_2_weight_bias = self.features_2_conv_2_weight_bias\n",
      "    conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_14, dequantize_per_tensor_default_15, features_2_conv_2_weight_bias);  dequantize_per_tensor_default_14 = dequantize_per_tensor_default_15 = features_2_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 1.0, 0, -128, 127, torch.int8);  conv2d_5 = None\n",
      "    dequantize_per_tensor_default_156 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_155 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_16 = None\n",
      "    _frozen_param6 = self._frozen_param6\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param6, 1.0, 0, -127, 127, torch.int8);  _frozen_param6 = None\n",
      "    features_3_conv_0_0_weight_bias = self.features_3_conv_0_0_weight_bias\n",
      "    conv2d_6 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_155, dequantize_per_tensor_default_17, features_3_conv_0_0_weight_bias);  dequantize_per_tensor_default_155 = dequantize_per_tensor_default_17 = features_3_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 1.0, 0, -128, 127, torch.int8);  conv2d_6 = None\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_18 = None\n",
      "    hardtanh__4 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_18, 0.0, 6.0);  dequantize_per_tensor_default_18 = None\n",
      "    quantize_per_tensor_default_19 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__4, 1.0, 0, -128, 127, torch.int8);  hardtanh__4 = None\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_19, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_19 = None\n",
      "    _frozen_param7 = self._frozen_param7\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param7, 1.0, 0, -127, 127, torch.int8);  _frozen_param7 = None\n",
      "    features_3_conv_1_0_weight_bias = self.features_3_conv_1_0_weight_bias\n",
      "    conv2d_7 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_19, dequantize_per_tensor_default_20, features_3_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_19 = dequantize_per_tensor_default_20 = features_3_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_7, 1.0, 0, -128, 127, torch.int8);  conv2d_7 = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
      "    hardtanh__5 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_21, 0.0, 6.0);  dequantize_per_tensor_default_21 = None\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__5, 1.0, 0, -128, 127, torch.int8);  hardtanh__5 = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_22 = None\n",
      "    _frozen_param8 = self._frozen_param8\n",
      "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param8, 1.0, 0, -127, 127, torch.int8);  _frozen_param8 = None\n",
      "    features_3_conv_2_weight_bias = self.features_3_conv_2_weight_bias\n",
      "    conv2d_8 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_22, dequantize_per_tensor_default_23, features_3_conv_2_weight_bias);  dequantize_per_tensor_default_22 = dequantize_per_tensor_default_23 = features_3_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_8, 1.0, 0, -128, 127, torch.int8);  conv2d_8 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_24 = None\n",
      "    add = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_156, dequantize_per_tensor_default_24);  dequantize_per_tensor_default_156 = dequantize_per_tensor_default_24 = None\n",
      "    quantize_per_tensor_default_25 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add, 1.0, 0, -128, 127, torch.int8);  add = None\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_25, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_25 = None\n",
      "    _frozen_param9 = self._frozen_param9\n",
      "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param9, 1.0, 0, -127, 127, torch.int8);  _frozen_param9 = None\n",
      "    features_4_conv_0_0_weight_bias = self.features_4_conv_0_0_weight_bias\n",
      "    conv2d_9 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_25, dequantize_per_tensor_default_26, features_4_conv_0_0_weight_bias);  dequantize_per_tensor_default_25 = dequantize_per_tensor_default_26 = features_4_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_9, 1.0, 0, -128, 127, torch.int8);  conv2d_9 = None\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
      "    hardtanh__6 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_27, 0.0, 6.0);  dequantize_per_tensor_default_27 = None\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__6, 1.0, 0, -128, 127, torch.int8);  hardtanh__6 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_28 = None\n",
      "    _frozen_param10 = self._frozen_param10\n",
      "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param10, 1.0, 0, -127, 127, torch.int8);  _frozen_param10 = None\n",
      "    features_4_conv_1_0_weight_bias = self.features_4_conv_1_0_weight_bias\n",
      "    conv2d_10 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_28, dequantize_per_tensor_default_29, features_4_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_28 = dequantize_per_tensor_default_29 = features_4_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_10, 1.0, 0, -128, 127, torch.int8);  conv2d_10 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_30 = None\n",
      "    hardtanh__7 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_30, 0.0, 6.0);  dequantize_per_tensor_default_30 = None\n",
      "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__7, 1.0, 0, -128, 127, torch.int8);  hardtanh__7 = None\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_31 = None\n",
      "    _frozen_param11 = self._frozen_param11\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param11, 1.0, 0, -127, 127, torch.int8);  _frozen_param11 = None\n",
      "    features_4_conv_2_weight_bias = self.features_4_conv_2_weight_bias\n",
      "    conv2d_11 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_31, dequantize_per_tensor_default_32, features_4_conv_2_weight_bias);  dequantize_per_tensor_default_31 = dequantize_per_tensor_default_32 = features_4_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_11, 1.0, 0, -128, 127, torch.int8);  conv2d_11 = None\n",
      "    dequantize_per_tensor_default_158 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_157 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
      "    _frozen_param12 = self._frozen_param12\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param12, 1.0, 0, -127, 127, torch.int8);  _frozen_param12 = None\n",
      "    features_5_conv_0_0_weight_bias = self.features_5_conv_0_0_weight_bias\n",
      "    conv2d_12 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_157, dequantize_per_tensor_default_34, features_5_conv_0_0_weight_bias);  dequantize_per_tensor_default_157 = dequantize_per_tensor_default_34 = features_5_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_35 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 1.0, 0, -128, 127, torch.int8);  conv2d_12 = None\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_35, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_35 = None\n",
      "    hardtanh__8 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_35, 0.0, 6.0);  dequantize_per_tensor_default_35 = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__8, 1.0, 0, -128, 127, torch.int8);  hardtanh__8 = None\n",
      "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_36 = None\n",
      "    _frozen_param13 = self._frozen_param13\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param13, 1.0, 0, -127, 127, torch.int8);  _frozen_param13 = None\n",
      "    features_5_conv_1_0_weight_bias = self.features_5_conv_1_0_weight_bias\n",
      "    conv2d_13 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_36, dequantize_per_tensor_default_37, features_5_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_36 = dequantize_per_tensor_default_37 = features_5_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_13, 1.0, 0, -128, 127, torch.int8);  conv2d_13 = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_38 = None\n",
      "    hardtanh__9 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_38, 0.0, 6.0);  dequantize_per_tensor_default_38 = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__9, 1.0, 0, -128, 127, torch.int8);  hardtanh__9 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
      "    _frozen_param14 = self._frozen_param14\n",
      "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param14, 1.0, 0, -127, 127, torch.int8);  _frozen_param14 = None\n",
      "    features_5_conv_2_weight_bias = self.features_5_conv_2_weight_bias\n",
      "    conv2d_14 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_39, dequantize_per_tensor_default_40, features_5_conv_2_weight_bias);  dequantize_per_tensor_default_39 = dequantize_per_tensor_default_40 = features_5_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_41 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_14, 1.0, 0, -128, 127, torch.int8);  conv2d_14 = None\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_41, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_41 = None\n",
      "    add_1 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_158, dequantize_per_tensor_default_41);  dequantize_per_tensor_default_158 = dequantize_per_tensor_default_41 = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_1, 1.0, 0, -128, 127, torch.int8);  add_1 = None\n",
      "    dequantize_per_tensor_default_160 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_159 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
      "    _frozen_param15 = self._frozen_param15\n",
      "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param15, 1.0, 0, -127, 127, torch.int8);  _frozen_param15 = None\n",
      "    features_6_conv_0_0_weight_bias = self.features_6_conv_0_0_weight_bias\n",
      "    conv2d_15 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_159, dequantize_per_tensor_default_43, features_6_conv_0_0_weight_bias);  dequantize_per_tensor_default_159 = dequantize_per_tensor_default_43 = features_6_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_15, 1.0, 0, -128, 127, torch.int8);  conv2d_15 = None\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_44 = None\n",
      "    hardtanh__10 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_44, 0.0, 6.0);  dequantize_per_tensor_default_44 = None\n",
      "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__10, 1.0, 0, -128, 127, torch.int8);  hardtanh__10 = None\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_45 = None\n",
      "    _frozen_param16 = self._frozen_param16\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param16, 1.0, 0, -127, 127, torch.int8);  _frozen_param16 = None\n",
      "    features_6_conv_1_0_weight_bias = self.features_6_conv_1_0_weight_bias\n",
      "    conv2d_16 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_45, dequantize_per_tensor_default_46, features_6_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_45 = dequantize_per_tensor_default_46 = features_6_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_16, 1.0, 0, -128, 127, torch.int8);  conv2d_16 = None\n",
      "    dequantize_per_tensor_default_47 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_47 = None\n",
      "    hardtanh__11 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_47, 0.0, 6.0);  dequantize_per_tensor_default_47 = None\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__11, 1.0, 0, -128, 127, torch.int8);  hardtanh__11 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_48 = None\n",
      "    _frozen_param17 = self._frozen_param17\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param17, 1.0, 0, -127, 127, torch.int8);  _frozen_param17 = None\n",
      "    features_6_conv_2_weight_bias = self.features_6_conv_2_weight_bias\n",
      "    conv2d_17 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_48, dequantize_per_tensor_default_49, features_6_conv_2_weight_bias);  dequantize_per_tensor_default_48 = dequantize_per_tensor_default_49 = features_6_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 1.0, 0, -128, 127, torch.int8);  conv2d_17 = None\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_50 = None\n",
      "    add_2 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_160, dequantize_per_tensor_default_50);  dequantize_per_tensor_default_160 = dequantize_per_tensor_default_50 = None\n",
      "    quantize_per_tensor_default_51 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_2, 1.0, 0, -128, 127, torch.int8);  add_2 = None\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_51, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_51 = None\n",
      "    _frozen_param18 = self._frozen_param18\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param18, 1.0, 0, -127, 127, torch.int8);  _frozen_param18 = None\n",
      "    features_7_conv_0_0_weight_bias = self.features_7_conv_0_0_weight_bias\n",
      "    conv2d_18 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_51, dequantize_per_tensor_default_52, features_7_conv_0_0_weight_bias);  dequantize_per_tensor_default_51 = dequantize_per_tensor_default_52 = features_7_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_18, 1.0, 0, -128, 127, torch.int8);  conv2d_18 = None\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_53 = None\n",
      "    hardtanh__12 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_53, 0.0, 6.0);  dequantize_per_tensor_default_53 = None\n",
      "    quantize_per_tensor_default_54 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__12, 1.0, 0, -128, 127, torch.int8);  hardtanh__12 = None\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_54 = None\n",
      "    _frozen_param19 = self._frozen_param19\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param19, 1.0, 0, -127, 127, torch.int8);  _frozen_param19 = None\n",
      "    features_7_conv_1_0_weight_bias = self.features_7_conv_1_0_weight_bias\n",
      "    conv2d_19 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_54, dequantize_per_tensor_default_55, features_7_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_54 = dequantize_per_tensor_default_55 = features_7_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 1.0, 0, -128, 127, torch.int8);  conv2d_19 = None\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_56 = None\n",
      "    hardtanh__13 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_56, 0.0, 6.0);  dequantize_per_tensor_default_56 = None\n",
      "    quantize_per_tensor_default_57 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__13, 1.0, 0, -128, 127, torch.int8);  hardtanh__13 = None\n",
      "    dequantize_per_tensor_default_57 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_57, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_57 = None\n",
      "    _frozen_param20 = self._frozen_param20\n",
      "    dequantize_per_tensor_default_58 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param20, 1.0, 0, -127, 127, torch.int8);  _frozen_param20 = None\n",
      "    features_7_conv_2_weight_bias = self.features_7_conv_2_weight_bias\n",
      "    conv2d_20 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_57, dequantize_per_tensor_default_58, features_7_conv_2_weight_bias);  dequantize_per_tensor_default_57 = dequantize_per_tensor_default_58 = features_7_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_59 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_20, 1.0, 0, -128, 127, torch.int8);  conv2d_20 = None\n",
      "    dequantize_per_tensor_default_162 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_59, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_161 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_59, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_59 = None\n",
      "    _frozen_param21 = self._frozen_param21\n",
      "    dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param21, 1.0, 0, -127, 127, torch.int8);  _frozen_param21 = None\n",
      "    features_8_conv_0_0_weight_bias = self.features_8_conv_0_0_weight_bias\n",
      "    conv2d_21 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_161, dequantize_per_tensor_default_60, features_8_conv_0_0_weight_bias);  dequantize_per_tensor_default_161 = dequantize_per_tensor_default_60 = features_8_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_61 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_21, 1.0, 0, -128, 127, torch.int8);  conv2d_21 = None\n",
      "    dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_61 = None\n",
      "    hardtanh__14 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_61, 0.0, 6.0);  dequantize_per_tensor_default_61 = None\n",
      "    quantize_per_tensor_default_62 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__14, 1.0, 0, -128, 127, torch.int8);  hardtanh__14 = None\n",
      "    dequantize_per_tensor_default_62 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_62, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_62 = None\n",
      "    _frozen_param22 = self._frozen_param22\n",
      "    dequantize_per_tensor_default_63 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param22, 1.0, 0, -127, 127, torch.int8);  _frozen_param22 = None\n",
      "    features_8_conv_1_0_weight_bias = self.features_8_conv_1_0_weight_bias\n",
      "    conv2d_22 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_62, dequantize_per_tensor_default_63, features_8_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_62 = dequantize_per_tensor_default_63 = features_8_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_64 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_22, 1.0, 0, -128, 127, torch.int8);  conv2d_22 = None\n",
      "    dequantize_per_tensor_default_64 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_64, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_64 = None\n",
      "    hardtanh__15 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_64, 0.0, 6.0);  dequantize_per_tensor_default_64 = None\n",
      "    quantize_per_tensor_default_65 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__15, 1.0, 0, -128, 127, torch.int8);  hardtanh__15 = None\n",
      "    dequantize_per_tensor_default_65 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_65, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_65 = None\n",
      "    _frozen_param23 = self._frozen_param23\n",
      "    dequantize_per_tensor_default_66 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param23, 1.0, 0, -127, 127, torch.int8);  _frozen_param23 = None\n",
      "    features_8_conv_2_weight_bias = self.features_8_conv_2_weight_bias\n",
      "    conv2d_23 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_65, dequantize_per_tensor_default_66, features_8_conv_2_weight_bias);  dequantize_per_tensor_default_65 = dequantize_per_tensor_default_66 = features_8_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_67 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_23, 1.0, 0, -128, 127, torch.int8);  conv2d_23 = None\n",
      "    dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_67 = None\n",
      "    add_3 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_162, dequantize_per_tensor_default_67);  dequantize_per_tensor_default_162 = dequantize_per_tensor_default_67 = None\n",
      "    quantize_per_tensor_default_68 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_3, 1.0, 0, -128, 127, torch.int8);  add_3 = None\n",
      "    dequantize_per_tensor_default_164 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_68, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_163 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_68, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_68 = None\n",
      "    _frozen_param24 = self._frozen_param24\n",
      "    dequantize_per_tensor_default_69 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param24, 1.0, 0, -127, 127, torch.int8);  _frozen_param24 = None\n",
      "    features_9_conv_0_0_weight_bias = self.features_9_conv_0_0_weight_bias\n",
      "    conv2d_24 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_163, dequantize_per_tensor_default_69, features_9_conv_0_0_weight_bias);  dequantize_per_tensor_default_163 = dequantize_per_tensor_default_69 = features_9_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_70 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_24, 1.0, 0, -128, 127, torch.int8);  conv2d_24 = None\n",
      "    dequantize_per_tensor_default_70 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_70, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_70 = None\n",
      "    hardtanh__16 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_70, 0.0, 6.0);  dequantize_per_tensor_default_70 = None\n",
      "    quantize_per_tensor_default_71 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__16, 1.0, 0, -128, 127, torch.int8);  hardtanh__16 = None\n",
      "    dequantize_per_tensor_default_71 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_71, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_71 = None\n",
      "    _frozen_param25 = self._frozen_param25\n",
      "    dequantize_per_tensor_default_72 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param25, 1.0, 0, -127, 127, torch.int8);  _frozen_param25 = None\n",
      "    features_9_conv_1_0_weight_bias = self.features_9_conv_1_0_weight_bias\n",
      "    conv2d_25 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_71, dequantize_per_tensor_default_72, features_9_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_71 = dequantize_per_tensor_default_72 = features_9_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_73 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_25, 1.0, 0, -128, 127, torch.int8);  conv2d_25 = None\n",
      "    dequantize_per_tensor_default_73 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_73 = None\n",
      "    hardtanh__17 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_73, 0.0, 6.0);  dequantize_per_tensor_default_73 = None\n",
      "    quantize_per_tensor_default_74 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__17, 1.0, 0, -128, 127, torch.int8);  hardtanh__17 = None\n",
      "    dequantize_per_tensor_default_74 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_74, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_74 = None\n",
      "    _frozen_param26 = self._frozen_param26\n",
      "    dequantize_per_tensor_default_75 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param26, 1.0, 0, -127, 127, torch.int8);  _frozen_param26 = None\n",
      "    features_9_conv_2_weight_bias = self.features_9_conv_2_weight_bias\n",
      "    conv2d_26 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_74, dequantize_per_tensor_default_75, features_9_conv_2_weight_bias);  dequantize_per_tensor_default_74 = dequantize_per_tensor_default_75 = features_9_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_76 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_26, 1.0, 0, -128, 127, torch.int8);  conv2d_26 = None\n",
      "    dequantize_per_tensor_default_76 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_76, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_76 = None\n",
      "    add_4 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_164, dequantize_per_tensor_default_76);  dequantize_per_tensor_default_164 = dequantize_per_tensor_default_76 = None\n",
      "    quantize_per_tensor_default_77 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_4, 1.0, 0, -128, 127, torch.int8);  add_4 = None\n",
      "    dequantize_per_tensor_default_166 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_77, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_165 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_77, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_77 = None\n",
      "    _frozen_param27 = self._frozen_param27\n",
      "    dequantize_per_tensor_default_78 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param27, 1.0, 0, -127, 127, torch.int8);  _frozen_param27 = None\n",
      "    features_10_conv_0_0_weight_bias = self.features_10_conv_0_0_weight_bias\n",
      "    conv2d_27 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_165, dequantize_per_tensor_default_78, features_10_conv_0_0_weight_bias);  dequantize_per_tensor_default_165 = dequantize_per_tensor_default_78 = features_10_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_79 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_27, 1.0, 0, -128, 127, torch.int8);  conv2d_27 = None\n",
      "    dequantize_per_tensor_default_79 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_79 = None\n",
      "    hardtanh__18 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_79, 0.0, 6.0);  dequantize_per_tensor_default_79 = None\n",
      "    quantize_per_tensor_default_80 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__18, 1.0, 0, -128, 127, torch.int8);  hardtanh__18 = None\n",
      "    dequantize_per_tensor_default_80 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_80, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_80 = None\n",
      "    _frozen_param28 = self._frozen_param28\n",
      "    dequantize_per_tensor_default_81 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param28, 1.0, 0, -127, 127, torch.int8);  _frozen_param28 = None\n",
      "    features_10_conv_1_0_weight_bias = self.features_10_conv_1_0_weight_bias\n",
      "    conv2d_28 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_80, dequantize_per_tensor_default_81, features_10_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_80 = dequantize_per_tensor_default_81 = features_10_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_82 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_28, 1.0, 0, -128, 127, torch.int8);  conv2d_28 = None\n",
      "    dequantize_per_tensor_default_82 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_82, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_82 = None\n",
      "    hardtanh__19 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_82, 0.0, 6.0);  dequantize_per_tensor_default_82 = None\n",
      "    quantize_per_tensor_default_83 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__19, 1.0, 0, -128, 127, torch.int8);  hardtanh__19 = None\n",
      "    dequantize_per_tensor_default_83 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_83, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_83 = None\n",
      "    _frozen_param29 = self._frozen_param29\n",
      "    dequantize_per_tensor_default_84 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param29, 1.0, 0, -127, 127, torch.int8);  _frozen_param29 = None\n",
      "    features_10_conv_2_weight_bias = self.features_10_conv_2_weight_bias\n",
      "    conv2d_29 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_83, dequantize_per_tensor_default_84, features_10_conv_2_weight_bias);  dequantize_per_tensor_default_83 = dequantize_per_tensor_default_84 = features_10_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_85 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_29, 1.0, 0, -128, 127, torch.int8);  conv2d_29 = None\n",
      "    dequantize_per_tensor_default_85 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_85 = None\n",
      "    add_5 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_166, dequantize_per_tensor_default_85);  dequantize_per_tensor_default_166 = dequantize_per_tensor_default_85 = None\n",
      "    quantize_per_tensor_default_86 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_5, 1.0, 0, -128, 127, torch.int8);  add_5 = None\n",
      "    dequantize_per_tensor_default_86 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_86, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_86 = None\n",
      "    _frozen_param30 = self._frozen_param30\n",
      "    dequantize_per_tensor_default_87 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param30, 1.0, 0, -127, 127, torch.int8);  _frozen_param30 = None\n",
      "    features_11_conv_0_0_weight_bias = self.features_11_conv_0_0_weight_bias\n",
      "    conv2d_30 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_86, dequantize_per_tensor_default_87, features_11_conv_0_0_weight_bias);  dequantize_per_tensor_default_86 = dequantize_per_tensor_default_87 = features_11_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_88 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_30, 1.0, 0, -128, 127, torch.int8);  conv2d_30 = None\n",
      "    dequantize_per_tensor_default_88 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_88, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_88 = None\n",
      "    hardtanh__20 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_88, 0.0, 6.0);  dequantize_per_tensor_default_88 = None\n",
      "    quantize_per_tensor_default_89 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__20, 1.0, 0, -128, 127, torch.int8);  hardtanh__20 = None\n",
      "    dequantize_per_tensor_default_89 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_89, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_89 = None\n",
      "    _frozen_param31 = self._frozen_param31\n",
      "    dequantize_per_tensor_default_90 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param31, 1.0, 0, -127, 127, torch.int8);  _frozen_param31 = None\n",
      "    features_11_conv_1_0_weight_bias = self.features_11_conv_1_0_weight_bias\n",
      "    conv2d_31 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_89, dequantize_per_tensor_default_90, features_11_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_89 = dequantize_per_tensor_default_90 = features_11_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_91 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_31, 1.0, 0, -128, 127, torch.int8);  conv2d_31 = None\n",
      "    dequantize_per_tensor_default_91 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_91 = None\n",
      "    hardtanh__21 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_91, 0.0, 6.0);  dequantize_per_tensor_default_91 = None\n",
      "    quantize_per_tensor_default_92 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__21, 1.0, 0, -128, 127, torch.int8);  hardtanh__21 = None\n",
      "    dequantize_per_tensor_default_92 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_92, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_92 = None\n",
      "    _frozen_param32 = self._frozen_param32\n",
      "    dequantize_per_tensor_default_93 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param32, 1.0, 0, -127, 127, torch.int8);  _frozen_param32 = None\n",
      "    features_11_conv_2_weight_bias = self.features_11_conv_2_weight_bias\n",
      "    conv2d_32 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_92, dequantize_per_tensor_default_93, features_11_conv_2_weight_bias);  dequantize_per_tensor_default_92 = dequantize_per_tensor_default_93 = features_11_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_94 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_32, 1.0, 0, -128, 127, torch.int8);  conv2d_32 = None\n",
      "    dequantize_per_tensor_default_168 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_94, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_167 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_94, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_94 = None\n",
      "    _frozen_param33 = self._frozen_param33\n",
      "    dequantize_per_tensor_default_95 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param33, 1.0, 0, -127, 127, torch.int8);  _frozen_param33 = None\n",
      "    features_12_conv_0_0_weight_bias = self.features_12_conv_0_0_weight_bias\n",
      "    conv2d_33 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_167, dequantize_per_tensor_default_95, features_12_conv_0_0_weight_bias);  dequantize_per_tensor_default_167 = dequantize_per_tensor_default_95 = features_12_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_96 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_33, 1.0, 0, -128, 127, torch.int8);  conv2d_33 = None\n",
      "    dequantize_per_tensor_default_96 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_96, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_96 = None\n",
      "    hardtanh__22 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_96, 0.0, 6.0);  dequantize_per_tensor_default_96 = None\n",
      "    quantize_per_tensor_default_97 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__22, 1.0, 0, -128, 127, torch.int8);  hardtanh__22 = None\n",
      "    dequantize_per_tensor_default_97 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_97 = None\n",
      "    _frozen_param34 = self._frozen_param34\n",
      "    dequantize_per_tensor_default_98 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param34, 1.0, 0, -127, 127, torch.int8);  _frozen_param34 = None\n",
      "    features_12_conv_1_0_weight_bias = self.features_12_conv_1_0_weight_bias\n",
      "    conv2d_34 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_97, dequantize_per_tensor_default_98, features_12_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_97 = dequantize_per_tensor_default_98 = features_12_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_99 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_34, 1.0, 0, -128, 127, torch.int8);  conv2d_34 = None\n",
      "    dequantize_per_tensor_default_99 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_99, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_99 = None\n",
      "    hardtanh__23 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_99, 0.0, 6.0);  dequantize_per_tensor_default_99 = None\n",
      "    quantize_per_tensor_default_100 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__23, 1.0, 0, -128, 127, torch.int8);  hardtanh__23 = None\n",
      "    dequantize_per_tensor_default_100 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_100, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_100 = None\n",
      "    _frozen_param35 = self._frozen_param35\n",
      "    dequantize_per_tensor_default_101 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param35, 1.0, 0, -127, 127, torch.int8);  _frozen_param35 = None\n",
      "    features_12_conv_2_weight_bias = self.features_12_conv_2_weight_bias\n",
      "    conv2d_35 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_100, dequantize_per_tensor_default_101, features_12_conv_2_weight_bias);  dequantize_per_tensor_default_100 = dequantize_per_tensor_default_101 = features_12_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_102 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_35, 1.0, 0, -128, 127, torch.int8);  conv2d_35 = None\n",
      "    dequantize_per_tensor_default_102 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_102, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_102 = None\n",
      "    add_6 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_168, dequantize_per_tensor_default_102);  dequantize_per_tensor_default_168 = dequantize_per_tensor_default_102 = None\n",
      "    quantize_per_tensor_default_103 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_6, 1.0, 0, -128, 127, torch.int8);  add_6 = None\n",
      "    dequantize_per_tensor_default_170 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_169 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_103 = None\n",
      "    _frozen_param36 = self._frozen_param36\n",
      "    dequantize_per_tensor_default_104 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param36, 1.0, 0, -127, 127, torch.int8);  _frozen_param36 = None\n",
      "    features_13_conv_0_0_weight_bias = self.features_13_conv_0_0_weight_bias\n",
      "    conv2d_36 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_169, dequantize_per_tensor_default_104, features_13_conv_0_0_weight_bias);  dequantize_per_tensor_default_169 = dequantize_per_tensor_default_104 = features_13_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_105 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_36, 1.0, 0, -128, 127, torch.int8);  conv2d_36 = None\n",
      "    dequantize_per_tensor_default_105 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_105, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_105 = None\n",
      "    hardtanh__24 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_105, 0.0, 6.0);  dequantize_per_tensor_default_105 = None\n",
      "    quantize_per_tensor_default_106 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__24, 1.0, 0, -128, 127, torch.int8);  hardtanh__24 = None\n",
      "    dequantize_per_tensor_default_106 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_106, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_106 = None\n",
      "    _frozen_param37 = self._frozen_param37\n",
      "    dequantize_per_tensor_default_107 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param37, 1.0, 0, -127, 127, torch.int8);  _frozen_param37 = None\n",
      "    features_13_conv_1_0_weight_bias = self.features_13_conv_1_0_weight_bias\n",
      "    conv2d_37 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_106, dequantize_per_tensor_default_107, features_13_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_106 = dequantize_per_tensor_default_107 = features_13_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_108 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_37, 1.0, 0, -128, 127, torch.int8);  conv2d_37 = None\n",
      "    dequantize_per_tensor_default_108 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_108, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_108 = None\n",
      "    hardtanh__25 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_108, 0.0, 6.0);  dequantize_per_tensor_default_108 = None\n",
      "    quantize_per_tensor_default_109 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__25, 1.0, 0, -128, 127, torch.int8);  hardtanh__25 = None\n",
      "    dequantize_per_tensor_default_109 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_109, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_109 = None\n",
      "    _frozen_param38 = self._frozen_param38\n",
      "    dequantize_per_tensor_default_110 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param38, 1.0, 0, -127, 127, torch.int8);  _frozen_param38 = None\n",
      "    features_13_conv_2_weight_bias = self.features_13_conv_2_weight_bias\n",
      "    conv2d_38 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_109, dequantize_per_tensor_default_110, features_13_conv_2_weight_bias);  dequantize_per_tensor_default_109 = dequantize_per_tensor_default_110 = features_13_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_111 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_38, 1.0, 0, -128, 127, torch.int8);  conv2d_38 = None\n",
      "    dequantize_per_tensor_default_111 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_111, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_111 = None\n",
      "    add_7 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_170, dequantize_per_tensor_default_111);  dequantize_per_tensor_default_170 = dequantize_per_tensor_default_111 = None\n",
      "    quantize_per_tensor_default_112 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_7, 1.0, 0, -128, 127, torch.int8);  add_7 = None\n",
      "    dequantize_per_tensor_default_112 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_112, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_112 = None\n",
      "    _frozen_param39 = self._frozen_param39\n",
      "    dequantize_per_tensor_default_113 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param39, 1.0, 0, -127, 127, torch.int8);  _frozen_param39 = None\n",
      "    features_14_conv_0_0_weight_bias = self.features_14_conv_0_0_weight_bias\n",
      "    conv2d_39 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_112, dequantize_per_tensor_default_113, features_14_conv_0_0_weight_bias);  dequantize_per_tensor_default_112 = dequantize_per_tensor_default_113 = features_14_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_114 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_39, 1.0, 0, -128, 127, torch.int8);  conv2d_39 = None\n",
      "    dequantize_per_tensor_default_114 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_114, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_114 = None\n",
      "    hardtanh__26 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_114, 0.0, 6.0);  dequantize_per_tensor_default_114 = None\n",
      "    quantize_per_tensor_default_115 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__26, 1.0, 0, -128, 127, torch.int8);  hardtanh__26 = None\n",
      "    dequantize_per_tensor_default_115 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_115, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_115 = None\n",
      "    _frozen_param40 = self._frozen_param40\n",
      "    dequantize_per_tensor_default_116 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param40, 1.0, 0, -127, 127, torch.int8);  _frozen_param40 = None\n",
      "    features_14_conv_1_0_weight_bias = self.features_14_conv_1_0_weight_bias\n",
      "    conv2d_40 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_115, dequantize_per_tensor_default_116, features_14_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_115 = dequantize_per_tensor_default_116 = features_14_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_117 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_40, 1.0, 0, -128, 127, torch.int8);  conv2d_40 = None\n",
      "    dequantize_per_tensor_default_117 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_117, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_117 = None\n",
      "    hardtanh__27 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_117, 0.0, 6.0);  dequantize_per_tensor_default_117 = None\n",
      "    quantize_per_tensor_default_118 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__27, 1.0, 0, -128, 127, torch.int8);  hardtanh__27 = None\n",
      "    dequantize_per_tensor_default_118 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_118, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_118 = None\n",
      "    _frozen_param41 = self._frozen_param41\n",
      "    dequantize_per_tensor_default_119 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param41, 1.0, 0, -127, 127, torch.int8);  _frozen_param41 = None\n",
      "    features_14_conv_2_weight_bias = self.features_14_conv_2_weight_bias\n",
      "    conv2d_41 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_118, dequantize_per_tensor_default_119, features_14_conv_2_weight_bias);  dequantize_per_tensor_default_118 = dequantize_per_tensor_default_119 = features_14_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_120 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_41, 1.0, 0, -128, 127, torch.int8);  conv2d_41 = None\n",
      "    dequantize_per_tensor_default_172 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_120, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_171 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_120, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_120 = None\n",
      "    _frozen_param42 = self._frozen_param42\n",
      "    dequantize_per_tensor_default_121 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param42, 1.0, 0, -127, 127, torch.int8);  _frozen_param42 = None\n",
      "    features_15_conv_0_0_weight_bias = self.features_15_conv_0_0_weight_bias\n",
      "    conv2d_42 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_171, dequantize_per_tensor_default_121, features_15_conv_0_0_weight_bias);  dequantize_per_tensor_default_171 = dequantize_per_tensor_default_121 = features_15_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_122 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_42, 1.0, 0, -128, 127, torch.int8);  conv2d_42 = None\n",
      "    dequantize_per_tensor_default_122 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_122, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_122 = None\n",
      "    hardtanh__28 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_122, 0.0, 6.0);  dequantize_per_tensor_default_122 = None\n",
      "    quantize_per_tensor_default_123 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__28, 1.0, 0, -128, 127, torch.int8);  hardtanh__28 = None\n",
      "    dequantize_per_tensor_default_123 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_123, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_123 = None\n",
      "    _frozen_param43 = self._frozen_param43\n",
      "    dequantize_per_tensor_default_124 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param43, 1.0, 0, -127, 127, torch.int8);  _frozen_param43 = None\n",
      "    features_15_conv_1_0_weight_bias = self.features_15_conv_1_0_weight_bias\n",
      "    conv2d_43 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_123, dequantize_per_tensor_default_124, features_15_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_123 = dequantize_per_tensor_default_124 = features_15_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_125 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_43, 1.0, 0, -128, 127, torch.int8);  conv2d_43 = None\n",
      "    dequantize_per_tensor_default_125 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_125 = None\n",
      "    hardtanh__29 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_125, 0.0, 6.0);  dequantize_per_tensor_default_125 = None\n",
      "    quantize_per_tensor_default_126 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__29, 1.0, 0, -128, 127, torch.int8);  hardtanh__29 = None\n",
      "    dequantize_per_tensor_default_126 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_126, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_126 = None\n",
      "    _frozen_param44 = self._frozen_param44\n",
      "    dequantize_per_tensor_default_127 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param44, 1.0, 0, -127, 127, torch.int8);  _frozen_param44 = None\n",
      "    features_15_conv_2_weight_bias = self.features_15_conv_2_weight_bias\n",
      "    conv2d_44 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_126, dequantize_per_tensor_default_127, features_15_conv_2_weight_bias);  dequantize_per_tensor_default_126 = dequantize_per_tensor_default_127 = features_15_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_128 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_44, 1.0, 0, -128, 127, torch.int8);  conv2d_44 = None\n",
      "    dequantize_per_tensor_default_128 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_128, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_128 = None\n",
      "    add_8 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_172, dequantize_per_tensor_default_128);  dequantize_per_tensor_default_172 = dequantize_per_tensor_default_128 = None\n",
      "    quantize_per_tensor_default_129 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_8, 1.0, 0, -128, 127, torch.int8);  add_8 = None\n",
      "    dequantize_per_tensor_default_174 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_129, 1.0, 0, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_173 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_129, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_129 = None\n",
      "    _frozen_param45 = self._frozen_param45\n",
      "    dequantize_per_tensor_default_130 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param45, 1.0, 0, -127, 127, torch.int8);  _frozen_param45 = None\n",
      "    features_16_conv_0_0_weight_bias = self.features_16_conv_0_0_weight_bias\n",
      "    conv2d_45 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_173, dequantize_per_tensor_default_130, features_16_conv_0_0_weight_bias);  dequantize_per_tensor_default_173 = dequantize_per_tensor_default_130 = features_16_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_131 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_45, 1.0, 0, -128, 127, torch.int8);  conv2d_45 = None\n",
      "    dequantize_per_tensor_default_131 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_131 = None\n",
      "    hardtanh__30 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_131, 0.0, 6.0);  dequantize_per_tensor_default_131 = None\n",
      "    quantize_per_tensor_default_132 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__30, 1.0, 0, -128, 127, torch.int8);  hardtanh__30 = None\n",
      "    dequantize_per_tensor_default_132 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_132, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_132 = None\n",
      "    _frozen_param46 = self._frozen_param46\n",
      "    dequantize_per_tensor_default_133 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param46, 1.0, 0, -127, 127, torch.int8);  _frozen_param46 = None\n",
      "    features_16_conv_1_0_weight_bias = self.features_16_conv_1_0_weight_bias\n",
      "    conv2d_46 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_132, dequantize_per_tensor_default_133, features_16_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_132 = dequantize_per_tensor_default_133 = features_16_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_134 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_46, 1.0, 0, -128, 127, torch.int8);  conv2d_46 = None\n",
      "    dequantize_per_tensor_default_134 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_134, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_134 = None\n",
      "    hardtanh__31 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_134, 0.0, 6.0);  dequantize_per_tensor_default_134 = None\n",
      "    quantize_per_tensor_default_135 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__31, 1.0, 0, -128, 127, torch.int8);  hardtanh__31 = None\n",
      "    dequantize_per_tensor_default_135 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_135, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_135 = None\n",
      "    _frozen_param47 = self._frozen_param47\n",
      "    dequantize_per_tensor_default_136 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param47, 1.0, 0, -127, 127, torch.int8);  _frozen_param47 = None\n",
      "    features_16_conv_2_weight_bias = self.features_16_conv_2_weight_bias\n",
      "    conv2d_47 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_135, dequantize_per_tensor_default_136, features_16_conv_2_weight_bias);  dequantize_per_tensor_default_135 = dequantize_per_tensor_default_136 = features_16_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_137 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_47, 1.0, 0, -128, 127, torch.int8);  conv2d_47 = None\n",
      "    dequantize_per_tensor_default_137 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_137 = None\n",
      "    add_9 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_174, dequantize_per_tensor_default_137);  dequantize_per_tensor_default_174 = dequantize_per_tensor_default_137 = None\n",
      "    quantize_per_tensor_default_138 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_9, 1.0, 0, -128, 127, torch.int8);  add_9 = None\n",
      "    dequantize_per_tensor_default_138 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_138, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_138 = None\n",
      "    _frozen_param48 = self._frozen_param48\n",
      "    dequantize_per_tensor_default_139 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param48, 1.0, 0, -127, 127, torch.int8);  _frozen_param48 = None\n",
      "    features_17_conv_0_0_weight_bias = self.features_17_conv_0_0_weight_bias\n",
      "    conv2d_48 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_138, dequantize_per_tensor_default_139, features_17_conv_0_0_weight_bias);  dequantize_per_tensor_default_138 = dequantize_per_tensor_default_139 = features_17_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_140 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_48, 1.0, 0, -128, 127, torch.int8);  conv2d_48 = None\n",
      "    dequantize_per_tensor_default_140 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_140, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_140 = None\n",
      "    hardtanh__32 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_140, 0.0, 6.0);  dequantize_per_tensor_default_140 = None\n",
      "    quantize_per_tensor_default_141 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__32, 1.0, 0, -128, 127, torch.int8);  hardtanh__32 = None\n",
      "    dequantize_per_tensor_default_141 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_141, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_141 = None\n",
      "    _frozen_param49 = self._frozen_param49\n",
      "    dequantize_per_tensor_default_142 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param49, 1.0, 0, -127, 127, torch.int8);  _frozen_param49 = None\n",
      "    features_17_conv_1_0_weight_bias = self.features_17_conv_1_0_weight_bias\n",
      "    conv2d_49 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_141, dequantize_per_tensor_default_142, features_17_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_141 = dequantize_per_tensor_default_142 = features_17_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_143 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_49, 1.0, 0, -128, 127, torch.int8);  conv2d_49 = None\n",
      "    dequantize_per_tensor_default_143 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_143 = None\n",
      "    hardtanh__33 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_143, 0.0, 6.0);  dequantize_per_tensor_default_143 = None\n",
      "    quantize_per_tensor_default_144 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__33, 1.0, 0, -128, 127, torch.int8);  hardtanh__33 = None\n",
      "    dequantize_per_tensor_default_144 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_144, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_144 = None\n",
      "    _frozen_param50 = self._frozen_param50\n",
      "    dequantize_per_tensor_default_145 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param50, 1.0, 0, -127, 127, torch.int8);  _frozen_param50 = None\n",
      "    features_17_conv_2_weight_bias = self.features_17_conv_2_weight_bias\n",
      "    conv2d_50 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_144, dequantize_per_tensor_default_145, features_17_conv_2_weight_bias);  dequantize_per_tensor_default_144 = dequantize_per_tensor_default_145 = features_17_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_146 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_50, 1.0, 0, -128, 127, torch.int8);  conv2d_50 = None\n",
      "    dequantize_per_tensor_default_146 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_146, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_146 = None\n",
      "    _frozen_param51 = self._frozen_param51\n",
      "    dequantize_per_tensor_default_147 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param51, 1.0, 0, -127, 127, torch.int8);  _frozen_param51 = None\n",
      "    features_18_0_weight_bias = self.features_18_0_weight_bias\n",
      "    conv2d_51 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_146, dequantize_per_tensor_default_147, features_18_0_weight_bias);  dequantize_per_tensor_default_146 = dequantize_per_tensor_default_147 = features_18_0_weight_bias = None\n",
      "    quantize_per_tensor_default_148 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_51, 1.0, 0, -128, 127, torch.int8);  conv2d_51 = None\n",
      "    dequantize_per_tensor_default_148 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_148, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_148 = None\n",
      "    hardtanh__34 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_148, 0.0, 6.0);  dequantize_per_tensor_default_148 = None\n",
      "    quantize_per_tensor_default_149 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__34, 1.0, 0, -128, 127, torch.int8);  hardtanh__34 = None\n",
      "    dequantize_per_tensor_default_149 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_149 = None\n",
      "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_default_149, [1, 1]);  dequantize_per_tensor_default_149 = None\n",
      "    quantize_per_tensor_default_150 = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 1.0, 0, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
      "    dequantize_per_tensor_default_150 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_150, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_150 = None\n",
      "    flatten = torch.ops.aten.flatten.using_ints(dequantize_per_tensor_default_150, 1);  dequantize_per_tensor_default_150 = None\n",
      "    quantize_per_tensor_default_151 = torch.ops.quantized_decomposed.quantize_per_tensor.default(flatten, 1.0, 0, -128, 127, torch.int8);  flatten = None\n",
      "    dequantize_per_tensor_default_151 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_151, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_151 = None\n",
      "    dropout = torch.ops.aten.dropout.default(dequantize_per_tensor_default_151, 0.2, False);  dequantize_per_tensor_default_151 = None\n",
      "    quantize_per_tensor_default_152 = torch.ops.quantized_decomposed.quantize_per_tensor.default(dropout, 1.0, 0, -128, 127, torch.int8);  dropout = None\n",
      "    dequantize_per_tensor_default_152 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_152, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_152 = None\n",
      "    _frozen_param52 = self._frozen_param52\n",
      "    dequantize_per_tensor_default_153 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param52, 1.0, 0, -127, 127, torch.int8);  _frozen_param52 = None\n",
      "    _param_constant157 = self.classifier_1_bias\n",
      "    linear = torch.ops.aten.linear.default(dequantize_per_tensor_default_152, dequantize_per_tensor_default_153, _param_constant157);  dequantize_per_tensor_default_152 = dequantize_per_tensor_default_153 = _param_constant157 = None\n",
      "    quantize_per_tensor_default_154 = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 1.0, 0, -128, 127, torch.int8);  linear = None\n",
      "    dequantize_per_tensor_default_154 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_154, 1.0, 0, -128, 127, torch.int8);  quantize_per_tensor_default_154 = None\n",
      "    return pytree.tree_unflatten([dequantize_per_tensor_default_154], self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa35037123/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1272: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/home/aa35037123/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/ao/quantization/utils.py:339: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f'device: {device}')\n",
    "device = torch.device('cpu')\n",
    "weight_path = '/home/aa35037123/Wesley/edge_ai/lab3/mobilenetv2_0.963.pth'\n",
    "model = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "model.to('cpu')\n",
    "print(next(model.parameters()).is_cuda)\n",
    "model.eval()\n",
    "example_inputs = (torch.randn(1, 3, 224, 224),)\n",
    "exported_model = capture_pre_autograd_graph(model, example_inputs)\n",
    "# Step 2. quantization\n",
    "from torch.ao.quantization.quantize_pt2e import (\n",
    "  prepare_pt2e,\n",
    "  convert_pt2e,\n",
    ")\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "  XNNPACKQuantizer,\n",
    "  get_symmetric_quantization_config,\n",
    ")\n",
    "# from torch.ao.quantization.quantizer import (\n",
    "#   XNNPACKQuantizer,\n",
    "#   get_symmetric_quantization_config,\n",
    "# )\n",
    "# backend developer will write their own Quantizer and expose methods to allow\n",
    "# users to express how they\n",
    "# want the model to be quantized\n",
    "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())\n",
    "prepared_model = prepare_pt2e(exported_model, quantizer)\n",
    "# print(prepared_model.graph)\n",
    "# calibration omitted\n",
    "calibrate(prepared_model, test_loader)  # run calibration on sample data\n",
    "ptq_quantized_model = convert_pt2e(prepared_model)\n",
    "print(ptq_quantized_model)\n",
    "# we have a model with aten ops doing integer computations when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modle has been export!\n"
     ]
    }
   ],
   "source": [
    "# Export the model and Save ExportedProgram\n",
    "pt2e_quantized_model_file_path =  \"./mobilenet_quantized.pt\"\n",
    "# capture the model to get an ExportedProgram\n",
    "example_inputs = (torch.randn(1, 3, 224, 224),)\n",
    "quantized_ep = torch.export.export(ptq_quantized_model, example_inputs)\n",
    "# use torch.export.save to save an ExportedProgram\n",
    "torch.export.save(quantized_ep, pt2e_quantized_model_file_path)\n",
    "print('Modle has been export!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected input at *args[0].shape[0] to be equal to 1, but got 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loaded_quantized_ep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexport\u001b[38;5;241m.\u001b[39mload(pt2e_quantized_model_file_path)\n\u001b[1;32m      2\u001b[0m loaded_quantized_model \u001b[38;5;241m=\u001b[39m loaded_quantized_ep\u001b[38;5;241m.\u001b[39mmodule()\n\u001b[0;32m----> 3\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_quantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m      8\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/fx/graph_module.py:737\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/fx/graph_module.py:317\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: TRY200\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/fx/graph_module.py:304\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;241m*\u001b[39m_global_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1559\u001b[0m ):\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks_with_kwargs:\n\u001b[0;32m-> 1561\u001b[0m         args_kwargs_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m args_kwargs_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1563\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_kwargs_result, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_kwargs_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/_dynamo/external_utils.py:36\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/export/_unlift.py:32\u001b[0m, in \u001b[0;36m_check_input_constraints_pre_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m received_spec \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_spec:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(  \u001b[38;5;66;03m# noqa: TRY200\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to flatten user inputs with exported input tree spec: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_spec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut actually got inputs with tree spec of: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_spec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_check_input_constraints_for_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplaceholder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args_with_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab3/lib/python3.10/site-packages/torch/_export/utils.py:129\u001b[0m, in \u001b[0;36m_check_input_constraints_for_graph\u001b[0;34m(input_placeholders, flat_args_with_path, range_constraints)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m arg_dim \u001b[38;5;241m!=\u001b[39m node_dim:\n\u001b[0;32m--> 129\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_keystr(key_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.shape[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to be equal to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m                 )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_val, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(arg) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m(node_val) \u001b[38;5;129;01mor\u001b[39;00m arg \u001b[38;5;241m!=\u001b[39m node_val:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected input at *args[0].shape[0] to be equal to 1, but got 16"
     ]
    }
   ],
   "source": [
    "loaded_quantized_ep = torch.export.load(pt2e_quantized_model_file_path)\n",
    "loaded_quantized_model = loaded_quantized_ep.module()\n",
    "acc = evaluate_model(loaded_quantized_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
