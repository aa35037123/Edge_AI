{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdC9V9xB10Gt"
      },
      "source": [
        "# **Template for Torch-Pruning**\n",
        "\n",
        "This template is just built for your convinience.\n",
        "\n",
        "You are not required to follow the steps and method given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7jfw5rNimfwu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_pruning in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (1.3.7)\n",
            "Requirement already satisfied: torch in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch_pruning) (2.2.1)\n",
            "Requirement already satisfied: numpy in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch_pruning) (1.26.4)\n",
            "Requirement already satisfied: filelock in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (1.12)\n",
            "Requirement already satisfied: networkx in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from torch->torch_pruning) (2024.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from jinja2->torch->torch_pruning) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/aa35037123/miniconda3/envs/lab2/lib/python3.10/site-packages (from sympy->torch->torch_pruning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-LiF8Vrqm2FU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models import mobilenet_v2\n",
        "import torch_pruning as tp\n",
        "from functools import partial\n",
        "\n",
        "import copy\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from collections import OrderedDict, defaultdict\n",
        "from typing import Union, List\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.utils.data import DataLoader\n",
        "from torchprofile import profile_macs\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchprofile import profile_macs\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ411pYQhkw4"
      },
      "source": [
        "## A Minimal Example   \n",
        "In this section, you will perform channel pruning using the library [Torch-Pruning](https://github.com/VainF/Torch-Pruning).  \n",
        "\n",
        "The puuner in Torch-Pruning has three main functions: sparse training (optional), importance estimation, and parameter removal.  \n",
        "Torch-pruning offers two core features to support this process:\n",
        "\n",
        "tp.importance(): This criteria is utilized to measure the importance of weights.  \n",
        "\n",
        "tp.pruner(): This is a pruner used for the actual pruning of the parameters.  \n",
        "\n",
        "For detailed information on this process, please refer to this [tutorial](https://github.com/VainF/Torch-Pruning/wiki/4.-High%E2%80%90level-Pruners/). Additionally, a more practical example is available in [here](https://github.com/VainF/Torch-Pruning/blob/master/benchmarks/main.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9e8CpBhmph9"
      },
      "source": [
        "### 1. Load model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "umaWm4eYms6G"
      },
      "outputs": [],
      "source": [
        "model = torch.load('./mobilenetv2_0.963.pth', map_location=\"cpu\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSe6NDqqm_qN"
      },
      "source": [
        "### 2. Prepare a pruner\n",
        "By default, Torch-Pruning will automatically prune the last non-singleton dim of these parameters. If you want to customize this behaviour, please provide an `unwrapped_parameters` list as the following example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transforms = {\n",
        "    \"train\": Compose([\n",
        "      Resize((224, 224)),\n",
        "      ToTensor(),\n",
        "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"test\": Compose([\n",
        "      Resize((224, 224)),\n",
        "      ToTensor(),\n",
        "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset = {}\n",
        "for split in [\"train\", \"test\"]:\n",
        "  dataset[split] = CIFAR10(\n",
        "    root=\"data/cifar10\",\n",
        "    train=(split == \"train\"),\n",
        "    download=True,\n",
        "    transform=transforms[split],\n",
        "  )\n",
        "\n",
        "# You can apply your own batch_size\n",
        "dataloader = {}\n",
        "for split in ['train', 'test']:\n",
        "  dataloader[split] = DataLoader(\n",
        "    dataset[split],\n",
        "    batch_size=2,\n",
        "    shuffle=(split == 'train'),\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def progressive_pruning(pruner, model, speed_up, example_inputs, train_loader=None):\n",
        "    model.eval()\n",
        "    base_ops, _ = tp.utils.count_ops_and_params(model, example_inputs=example_inputs)\n",
        "    current_speed_up = 1\n",
        "    while current_speed_up < speed_up:\n",
        "        pruner.step()\n",
        "        pruned_ops, _ = tp.utils.count_ops_and_params(model, example_inputs=example_inputs)\n",
        "        current_speed_up = float(base_ops) / pruned_ops\n",
        "        if pruner.current_step == pruner.iterative_steps:\n",
        "            break\n",
        "    return current_speed_up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"./pruning_output\"\n",
        "def eval(model, test_loader, device=None, verbose=True):\n",
        "\n",
        "    num_samples = 0\n",
        "    num_correct = 0\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(test_loader, desc=\"eval\", leave=False,\n",
        "                                    disable=not verbose):\n",
        "            # Move the data from CPU to GPU\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "            # Inference\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Convert logits to class indices\n",
        "            outputs = outputs.argmax(dim=1)\n",
        "\n",
        "            # Update metrics\n",
        "            num_samples += targets.size(0)\n",
        "            num_correct += (outputs == targets).sum()\n",
        "\n",
        "    return (num_correct / num_samples * 100).item()\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs,\n",
        "    lr,\n",
        "    save_as=None,\n",
        "    \n",
        "    # For pruning\n",
        "    weight_decay=1e-4,\n",
        "    save_state_dict_only=True,\n",
        "    pruner=None,\n",
        "    device=None,\n",
        "    verbose=False\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "    if pruner is not None:\n",
        "        pruner.update_regularizer()\n",
        "    model.to(device)\n",
        "    best_acc = -1\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(tqdm(train_loader, desc='train', leave=False)):\n",
        "            # Move the data from CPU to GPU\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "            # Reset the gradients (from the last iteration)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward inference\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward propagation\n",
        "            loss.backward()\n",
        "\n",
        "            if pruner is not None:\n",
        "                pruner.regularize(model) # for sparsity learning\n",
        "\n",
        "            # Update optimizer and LR scheduler\n",
        "            optimizer.step()\n",
        "            if i % 10 == 0 and verbose:\n",
        "                print(\n",
        "                    \"Epoch {:d}/{:d}, iter {:d}/{:d}, loss={:.4f}, lr={:.4f}\".format(\n",
        "                        epoch,\n",
        "                        epochs,\n",
        "                        i,\n",
        "                        len(train_loader),\n",
        "                        loss.item(),\n",
        "                        optimizer.param_groups[0][\"lr\"],\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        if pruner is not None and isinstance(pruner, tp.pruner.GrowingRegPruner):\n",
        "            pruner.update_reg() # increase the strength of regularization\n",
        "            #print(pruner.group_reg[pruner._groups[0]])\n",
        "        \n",
        "        model.eval()\n",
        "        acc = eval(model, test_loader, device=device)\n",
        "        print(\n",
        "            \"Epoch {:d}/{:d}, Acc={:.4f}, lr={:.4f}\".format(\n",
        "                epoch, epochs, acc, optimizer.param_groups[0][\"lr\"]\n",
        "            )\n",
        "        )\n",
        "        if best_acc < acc:\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            \n",
        "            if save_as is None:\n",
        "                save_as = os.path.join(output_dir, \"{}_{}_{}.pth\".format('CIFAR10', 'mobilenet', 'group_norm'))\n",
        "\n",
        "            if save_state_dict_only:\n",
        "                torch.save(model.state_dict(), save_as)\n",
        "            else:\n",
        "                torch.save(model, save_as)\n",
        "            best_acc = acc\n",
        "        scheduler.step()\n",
        "    print(\"Best Acc=%.4f\" % (best_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "up4Y3mqCnEIR"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "# Importance criterion\n",
        "imp = tp.importance.GroupNormImportance(p=2) # or GroupTaylorImportance(), GroupHessianImportance(), etc.\n",
        "\n",
        "# Initialize a pruner with the model and the importance criterion\n",
        "example_inputs = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "unwrapped_parameters = []\n",
        "ignored_layers = []\n",
        "pruning_ratio_dict = {}\n",
        "for m in model.modules():\n",
        "  if isinstance(m, torch.nn.Linear) and m.out_features == NUM_CLASSES: # ignore the classifier\n",
        "    ignored_layers.append(m)\n",
        "  elif isinstance(m, torch.nn.modules.conv._ConvNd) and m.out_channels == NUM_CLASSES:\n",
        "            ignored_layers.append(m)\n",
        "\n",
        "pruner_entry = partial(tp.pruner.GroupNormPruner, global_pruning=False)\n",
        "pruner = pruner_entry(\n",
        "        model,\n",
        "        example_inputs,\n",
        "        importance=imp,\n",
        "        iterative_steps=400,\n",
        "        pruning_ratio=1.0,\n",
        "        pruning_ratio_dict=pruning_ratio_dict,\n",
        "        max_pruning_ratio=1.0,\n",
        "        ignored_layers=ignored_layers,\n",
        "        unwrapped_parameters=unwrapped_parameters,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1XmDH9ToKYO"
      },
      "source": [
        "### 3. Prune the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qmklPY2goMX2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base acc: 73.58999633789062\n",
            "Pruning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Params: 0.10 M => 0.05 M (44.65%)\n",
            "FLOPs: 18.53 M => 9.18 M (49.56%, 2.02X )\n",
            "Acc: 73.5900 => 10.0000\n",
            "The pruned model:\n",
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "          (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(1, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=11, bias=False)\n",
            "          (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(11, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(2, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=18, bias=False)\n",
            "          (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(18, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(2, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=18, bias=False)\n",
            "          (1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(18, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(3, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=23, bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(23, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(3, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=23, bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(23, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(3, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(23, 23, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=23, bias=False)\n",
            "          (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(23, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(7, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(48, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(7, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(48, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(7, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(48, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(7, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(48, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(11, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(72, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(11, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(72, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(11, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(72, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): Conv2dNormActivation(\n",
            "      (0): Conv2d(40, 161, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(161, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=161, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Summary:\n",
            "MFLOPs: \n",
            "9.181035\n",
            "Finetuning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/30, Acc=62.3600, lr=0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30, Acc=65.2200, lr=0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/30, Acc=67.3800, lr=0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/30, Acc=65.0600, lr=0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/30, Acc=63.7700, lr=0.0096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/30, Acc=69.3100, lr=0.0093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/30, Acc=67.7500, lr=0.0090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/30, Acc=69.0700, lr=0.0087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/30, Acc=68.9200, lr=0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/30, Acc=68.6200, lr=0.0079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/30, Acc=68.8400, lr=0.0075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30, Acc=70.3700, lr=0.0070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/30, Acc=67.8000, lr=0.0065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/30, Acc=71.1600, lr=0.0060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/30, Acc=70.4100, lr=0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/30, Acc=73.6100, lr=0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/30, Acc=70.8800, lr=0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/30, Acc=72.1500, lr=0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/30, Acc=74.3300, lr=0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/30, Acc=73.2600, lr=0.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/30, Acc=73.6500, lr=0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/30, Acc=74.4900, lr=0.0021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/30, Acc=76.4100, lr=0.0017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/30, Acc=77.0000, lr=0.0013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/30, Acc=76.9300, lr=0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/30, Acc=77.7800, lr=0.0007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/30, Acc=77.6700, lr=0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/30, Acc=78.6100, lr=0.0002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/30, Acc=78.7400, lr=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/30, Acc=78.9700, lr=0.0000\n",
            "Best Acc=78.9700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "total_epochs = 30\n",
        "lr = 0.01\n",
        "# Model size before pruning\n",
        "model.eval()\n",
        "\n",
        "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
        "base_acc = eval(model, dataloader['test'], device=device)\n",
        "print(f'base acc: {base_acc}')\n",
        "if isinstance(imp, tp.importance.GroupTaylorImportance):\n",
        "  # Taylor expansion requires gradients for importance estimation\n",
        "  loss = model(example_inputs).sum() # A dummy loss, please replace this line with your loss function and data!\n",
        "  loss.backward() # before pruner.step()\n",
        "\n",
        "print(\"Pruning...\")\n",
        "# prune\n",
        "progressive_pruning(pruner, model, speed_up=2, example_inputs=example_inputs, train_loader=dataloader['train'])\n",
        "\n",
        "# Parameter & MACs Counter\n",
        "pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
        "pruned_acc = eval(model, dataloader['test'], device=device)\n",
        "print(\"Params: {:.2f} M => {:.2f} M ({:.2f}%)\".format(\n",
        "                base_nparams / 1e6, pruned_nparams / 1e6, pruned_nparams / base_nparams * 100\n",
        "            ))\n",
        "print(\"FLOPs: {:.2f} M => {:.2f} M ({:.2f}%, {:.2f}X )\".format(\n",
        "                base_macs / 1e6,\n",
        "                pruned_macs / 1e6,\n",
        "                pruned_macs / base_macs * 100,\n",
        "                base_macs / pruned_macs,\n",
        "            ))\n",
        "print(\"Acc: {:.4f} => {:.4f}\".format(base_acc, pruned_acc))\n",
        "MFLOPs = pruned_macs/1e6\n",
        "print(\"The pruned model:\")\n",
        "print(model)\n",
        "print(\"Summary:\")\n",
        "print(\"MFLOPs: \")\n",
        "print(MFLOPs)\n",
        "\n",
        "# 2. Finetuning\n",
        "print('Finetuning...')\n",
        "train_model(\n",
        "                model,\n",
        "                train_loader=dataloader['train'],\n",
        "                test_loader=dataloader['test'],\n",
        "                epochs=total_epochs,\n",
        "                lr=lr,\n",
        "                save_as=None,\n",
        "                weight_decay=1e-4,\n",
        "                save_state_dict_only=False,\n",
        "                pruner=None,\n",
        "                device=device,\n",
        "                verbose=False\n",
        "            )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
