{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfRESKfRZzs3",
        "outputId": "59fcb1d4-11ac-415a-a558-7c8cc0f848b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install the newest version of torch, torchvision, and timm\n",
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata timm\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata timm"
      ],
      "metadata": {
        "id": "GjmY1ydrZls5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0060f27-cfa5-4cbd-f135-c27a36e9aa1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping timm as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Collecting torchdata\n",
            "  Using cached torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Collecting timm\n",
            "  Using cached timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.0 (from torch)\n",
            "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchtext, torchdata, torchaudio, timm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 timm-0.9.16 torch-2.3.0 torchaudio-2.3.0 torchdata-0.7.1 torchtext-0.18.0 torchvision-0.18.0 triton-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UVSaQdJvZiWT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch._export import capture_pre_autograd_graph\n",
        "\n",
        "from torchvision.models import mobilenet_v2\n",
        "# from torchvision.models.quantization import mobilenet_v2\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3HfU9hhrZiWU"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader,device):\n",
        "\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the test images: {accuracy}%')\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y4tO3t7BZiWV",
        "outputId": "87b1cfe1-6ac2-4582-b1ae-2f53f1397e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29783563.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize images to match MobileNet input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,drop_last=True)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "batch_size = 16\n",
        "train_loader, test_loader = prepare_data(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vO6QisM6ZiWV"
      },
      "outputs": [],
      "source": [
        "def calibrate(model, data_loader, device):\n",
        "    # model.eval()\n",
        "    # torch.ao.quantization.move_exported_model_to_train(model)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FN5LrZoJZiWW",
        "outputId": "b16f4ceb-006f-4889-a435-71778c5feecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "True\n",
            "GraphModule()\n",
            "\n",
            "\n",
            "\n",
            "def forward(self, x):\n",
            "    arg0, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
            "    arg0_1 = arg0\n",
            "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(arg0_1, 0.01864933781325817, -14, -128, 127, torch.int8);  arg0_1 = None\n",
            "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01864933781325817, -14, -128, 127, torch.int8);  quantize_per_tensor_default = None\n",
            "    _frozen_param0 = self._frozen_param0\n",
            "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param0, 0.01771945133805275, 0, -127, 127, torch.int8);  _frozen_param0 = None\n",
            "    conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_default_1, None, [2, 2], [1, 1]);  dequantize_per_tensor_default = dequantize_per_tensor_default_1 = None\n",
            "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.13380414247512817, -5, -128, 127, torch.int8);  conv2d = None\n",
            "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.13380414247512817, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None\n",
            "    _param_constant1 = self.features_0_1_weight\n",
            "    _param_constant2 = self.features_0_1_bias\n",
            "    _tensor_constant0 = self.features_0_1_running_mean\n",
            "    _tensor_constant1 = self.features_0_1_running_var\n",
            "    cudnn_batch_norm = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_2, _param_constant1, _param_constant2, _tensor_constant0, _tensor_constant1, False, 0.1, 1e-05);  dequantize_per_tensor_default_2 = _param_constant1 = _param_constant2 = _tensor_constant0 = _tensor_constant1 = None\n",
            "    getitem = cudnn_batch_norm[0];  cudnn_batch_norm = None\n",
            "    hardtanh_ = torch.ops.aten.hardtanh_.default(getitem, 0.0, 6.0);  getitem = None\n",
            "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh_, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh_ = None\n",
            "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
            "    _frozen_param1 = self._frozen_param1\n",
            "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param1, 0.026106514036655426, 0, -127, 127, torch.int8);  _frozen_param1 = None\n",
            "    conv2d_1 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor_default_4, None, [1, 1], [1, 1], [1, 1], 32);  dequantize_per_tensor_default_3 = dequantize_per_tensor_default_4 = None\n",
            "    quantize_per_tensor_default_5 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_1, 0.23578262329101562, 0, -128, 127, torch.int8);  conv2d_1 = None\n",
            "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 0.23578262329101562, 0, -128, 127, torch.int8);  quantize_per_tensor_default_5 = None\n",
            "    _param_constant4 = self.features_1_conv_0_1_weight\n",
            "    _param_constant5 = self.features_1_conv_0_1_bias\n",
            "    _tensor_constant2 = self.features_1_conv_0_1_running_mean\n",
            "    _tensor_constant3 = self.features_1_conv_0_1_running_var\n",
            "    cudnn_batch_norm_1 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_5, _param_constant4, _param_constant5, _tensor_constant2, _tensor_constant3, False, 0.1, 1e-05);  dequantize_per_tensor_default_5 = _param_constant4 = _param_constant5 = _tensor_constant2 = _tensor_constant3 = None\n",
            "    getitem_4 = cudnn_batch_norm_1[0];  cudnn_batch_norm_1 = None\n",
            "    hardtanh__1 = torch.ops.aten.hardtanh_.default(getitem_4, 0.0, 6.0);  getitem_4 = None\n",
            "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__1, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__1 = None\n",
            "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_6 = None\n",
            "    _frozen_param2 = self._frozen_param2\n",
            "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param2, 0.018680661916732788, 0, -127, 127, torch.int8);  _frozen_param2 = None\n",
            "    conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_6, dequantize_per_tensor_default_7);  dequantize_per_tensor_default_6 = dequantize_per_tensor_default_7 = None\n",
            "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.1417524814605713, -13, -128, 127, torch.int8);  conv2d_2 = None\n",
            "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.1417524814605713, -13, -128, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
            "    _param_constant7 = self.features_1_conv_2_weight\n",
            "    _param_constant8 = self.features_1_conv_2_bias\n",
            "    _tensor_constant4 = self.features_1_conv_2_running_mean\n",
            "    _tensor_constant5 = self.features_1_conv_2_running_var\n",
            "    cudnn_batch_norm_2 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_8, _param_constant7, _param_constant8, _tensor_constant4, _tensor_constant5, False, 0.1, 1e-05);  dequantize_per_tensor_default_8 = _param_constant7 = _param_constant8 = _tensor_constant4 = _tensor_constant5 = None\n",
            "    getitem_8 = cudnn_batch_norm_2[0];  cudnn_batch_norm_2 = None\n",
            "    quantize_per_tensor_default_9 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_8, 0.4211532771587372, 28, -128, 127, torch.int8);  getitem_8 = None\n",
            "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.4211532771587372, 28, -128, 127, torch.int8);  quantize_per_tensor_default_9 = None\n",
            "    _frozen_param3 = self._frozen_param3\n",
            "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param3, 0.012603089213371277, 0, -127, 127, torch.int8);  _frozen_param3 = None\n",
            "    conv2d_3 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_9, dequantize_per_tensor_default_10);  dequantize_per_tensor_default_9 = dequantize_per_tensor_default_10 = None\n",
            "    quantize_per_tensor_default_11 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_3, 0.6820625066757202, 1, -128, 127, torch.int8);  conv2d_3 = None\n",
            "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 0.6820625066757202, 1, -128, 127, torch.int8);  quantize_per_tensor_default_11 = None\n",
            "    _param_constant10 = self.features_2_conv_0_1_weight\n",
            "    _param_constant11 = self.features_2_conv_0_1_bias\n",
            "    _tensor_constant6 = self.features_2_conv_0_1_running_mean\n",
            "    _tensor_constant7 = self.features_2_conv_0_1_running_var\n",
            "    cudnn_batch_norm_3 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_11, _param_constant10, _param_constant11, _tensor_constant6, _tensor_constant7, False, 0.1, 1e-05);  dequantize_per_tensor_default_11 = _param_constant10 = _param_constant11 = _tensor_constant6 = _tensor_constant7 = None\n",
            "    getitem_12 = cudnn_batch_norm_3[0];  cudnn_batch_norm_3 = None\n",
            "    hardtanh__2 = torch.ops.aten.hardtanh_.default(getitem_12, 0.0, 6.0);  getitem_12 = None\n",
            "    quantize_per_tensor_default_12 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__2, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__2 = None\n",
            "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_12 = None\n",
            "    _frozen_param4 = self._frozen_param4\n",
            "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param4, 0.005727971438318491, 0, -127, 127, torch.int8);  _frozen_param4 = None\n",
            "    conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_12, dequantize_per_tensor_default_13, None, [2, 2], [1, 1], [1, 1], 96);  dequantize_per_tensor_default_12 = dequantize_per_tensor_default_13 = None\n",
            "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.10824650526046753, -5, -128, 127, torch.int8);  conv2d_4 = None\n",
            "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.10824650526046753, -5, -128, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
            "    _param_constant13 = self.features_2_conv_1_1_weight\n",
            "    _param_constant14 = self.features_2_conv_1_1_bias\n",
            "    _tensor_constant8 = self.features_2_conv_1_1_running_mean\n",
            "    _tensor_constant9 = self.features_2_conv_1_1_running_var\n",
            "    cudnn_batch_norm_4 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_14, _param_constant13, _param_constant14, _tensor_constant8, _tensor_constant9, False, 0.1, 1e-05);  dequantize_per_tensor_default_14 = _param_constant13 = _param_constant14 = _tensor_constant8 = _tensor_constant9 = None\n",
            "    getitem_16 = cudnn_batch_norm_4[0];  cudnn_batch_norm_4 = None\n",
            "    hardtanh__3 = torch.ops.aten.hardtanh_.default(getitem_16, 0.0, 6.0);  getitem_16 = None\n",
            "    quantize_per_tensor_default_15 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__3, 0.023494945839047432, -128, -128, 127, torch.int8);  hardtanh__3 = None\n",
            "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.023494945839047432, -128, -128, 127, torch.int8);  quantize_per_tensor_default_15 = None\n",
            "    _frozen_param5 = self._frozen_param5\n",
            "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param5, 0.015424797311425209, 0, -127, 127, torch.int8);  _frozen_param5 = None\n",
            "    conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_15, dequantize_per_tensor_default_16);  dequantize_per_tensor_default_15 = dequantize_per_tensor_default_16 = None\n",
            "    quantize_per_tensor_default_17 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.16204506158828735, -1, -128, 127, torch.int8);  conv2d_5 = None\n",
            "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_17, 0.16204506158828735, -1, -128, 127, torch.int8);  quantize_per_tensor_default_17 = None\n",
            "    _param_constant16 = self.features_2_conv_3_weight\n",
            "    _param_constant17 = self.features_2_conv_3_bias\n",
            "    _tensor_constant10 = self.features_2_conv_3_running_mean\n",
            "    _tensor_constant11 = self.features_2_conv_3_running_var\n",
            "    cudnn_batch_norm_5 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_17, _param_constant16, _param_constant17, _tensor_constant10, _tensor_constant11, False, 0.1, 1e-05);  dequantize_per_tensor_default_17 = _param_constant16 = _param_constant17 = _tensor_constant10 = _tensor_constant11 = None\n",
            "    getitem_20 = cudnn_batch_norm_5[0];  cudnn_batch_norm_5 = None\n",
            "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_20, 0.2666963040828705, -4, -128, 127, torch.int8);  getitem_20 = None\n",
            "    dequantize_per_tensor_default_173 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.2666963040828705, -4, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_172 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.2666963040828705, -4, -128, 127, torch.int8);  quantize_per_tensor_default_18 = None\n",
            "    _frozen_param6 = self._frozen_param6\n",
            "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param6, 0.010880573652684689, 0, -127, 127, torch.int8);  _frozen_param6 = None\n",
            "    conv2d_6 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_172, dequantize_per_tensor_default_19);  dequantize_per_tensor_default_172 = dequantize_per_tensor_default_19 = None\n",
            "    quantize_per_tensor_default_20 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 0.34095779061317444, 3, -128, 127, torch.int8);  conv2d_6 = None\n",
            "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.34095779061317444, 3, -128, 127, torch.int8);  quantize_per_tensor_default_20 = None\n",
            "    _param_constant19 = self.features_3_conv_0_1_weight\n",
            "    _param_constant20 = self.features_3_conv_0_1_bias\n",
            "    _tensor_constant12 = self.features_3_conv_0_1_running_mean\n",
            "    _tensor_constant13 = self.features_3_conv_0_1_running_var\n",
            "    cudnn_batch_norm_6 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_20, _param_constant19, _param_constant20, _tensor_constant12, _tensor_constant13, False, 0.1, 1e-05);  dequantize_per_tensor_default_20 = _param_constant19 = _param_constant20 = _tensor_constant12 = _tensor_constant13 = None\n",
            "    getitem_24 = cudnn_batch_norm_6[0];  cudnn_batch_norm_6 = None\n",
            "    hardtanh__4 = torch.ops.aten.hardtanh_.default(getitem_24, 0.0, 6.0);  getitem_24 = None\n",
            "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__4, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__4 = None\n",
            "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
            "    _frozen_param7 = self._frozen_param7\n",
            "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param7, 0.011101556941866875, 0, -127, 127, torch.int8);  _frozen_param7 = None\n",
            "    conv2d_7 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_21, dequantize_per_tensor_default_22, None, [1, 1], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_21 = dequantize_per_tensor_default_22 = None\n",
            "    quantize_per_tensor_default_23 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_7, 0.06804130226373672, 22, -128, 127, torch.int8);  conv2d_7 = None\n",
            "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.06804130226373672, 22, -128, 127, torch.int8);  quantize_per_tensor_default_23 = None\n",
            "    _param_constant22 = self.features_3_conv_1_1_weight\n",
            "    _param_constant23 = self.features_3_conv_1_1_bias\n",
            "    _tensor_constant14 = self.features_3_conv_1_1_running_mean\n",
            "    _tensor_constant15 = self.features_3_conv_1_1_running_var\n",
            "    cudnn_batch_norm_7 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_23, _param_constant22, _param_constant23, _tensor_constant14, _tensor_constant15, False, 0.1, 1e-05);  dequantize_per_tensor_default_23 = _param_constant22 = _param_constant23 = _tensor_constant14 = _tensor_constant15 = None\n",
            "    getitem_28 = cudnn_batch_norm_7[0];  cudnn_batch_norm_7 = None\n",
            "    hardtanh__5 = torch.ops.aten.hardtanh_.default(getitem_28, 0.0, 6.0);  getitem_28 = None\n",
            "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__5, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__5 = None\n",
            "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_24 = None\n",
            "    _frozen_param8 = self._frozen_param8\n",
            "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param8, 0.008840336464345455, 0, -127, 127, torch.int8);  _frozen_param8 = None\n",
            "    conv2d_8 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_24, dequantize_per_tensor_default_25);  dequantize_per_tensor_default_24 = dequantize_per_tensor_default_25 = None\n",
            "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_8, 0.13382656872272491, -9, -128, 127, torch.int8);  conv2d_8 = None\n",
            "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.13382656872272491, -9, -128, 127, torch.int8);  quantize_per_tensor_default_26 = None\n",
            "    _param_constant25 = self.features_3_conv_3_weight\n",
            "    _param_constant26 = self.features_3_conv_3_bias\n",
            "    _tensor_constant16 = self.features_3_conv_3_running_mean\n",
            "    _tensor_constant17 = self.features_3_conv_3_running_var\n",
            "    cudnn_batch_norm_8 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_26, _param_constant25, _param_constant26, _tensor_constant16, _tensor_constant17, False, 0.1, 1e-05);  dequantize_per_tensor_default_26 = _param_constant25 = _param_constant26 = _tensor_constant16 = _tensor_constant17 = None\n",
            "    getitem_32 = cudnn_batch_norm_8[0];  cudnn_batch_norm_8 = None\n",
            "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_32, 0.3578588366508484, -18, -128, 127, torch.int8);  getitem_32 = None\n",
            "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.3578588366508484, -18, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
            "    add = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_173, dequantize_per_tensor_default_27);  dequantize_per_tensor_default_173 = dequantize_per_tensor_default_27 = None\n",
            "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add, 0.37000876665115356, -8, -128, 127, torch.int8);  add = None\n",
            "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.37000876665115356, -8, -128, 127, torch.int8);  quantize_per_tensor_default_28 = None\n",
            "    _frozen_param9 = self._frozen_param9\n",
            "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param9, 0.012824663892388344, 0, -127, 127, torch.int8);  _frozen_param9 = None\n",
            "    conv2d_9 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_28, dequantize_per_tensor_default_29);  dequantize_per_tensor_default_28 = dequantize_per_tensor_default_29 = None\n",
            "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_9, 0.559560239315033, -1, -128, 127, torch.int8);  conv2d_9 = None\n",
            "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.559560239315033, -1, -128, 127, torch.int8);  quantize_per_tensor_default_30 = None\n",
            "    _param_constant28 = self.features_4_conv_0_1_weight\n",
            "    _param_constant29 = self.features_4_conv_0_1_bias\n",
            "    _tensor_constant18 = self.features_4_conv_0_1_running_mean\n",
            "    _tensor_constant19 = self.features_4_conv_0_1_running_var\n",
            "    cudnn_batch_norm_9 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_30, _param_constant28, _param_constant29, _tensor_constant18, _tensor_constant19, False, 0.1, 1e-05);  dequantize_per_tensor_default_30 = _param_constant28 = _param_constant29 = _tensor_constant18 = _tensor_constant19 = None\n",
            "    getitem_36 = cudnn_batch_norm_9[0];  cudnn_batch_norm_9 = None\n",
            "    hardtanh__6 = torch.ops.aten.hardtanh_.default(getitem_36, 0.0, 6.0);  getitem_36 = None\n",
            "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__6, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__6 = None\n",
            "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_31 = None\n",
            "    _frozen_param10 = self._frozen_param10\n",
            "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param10, 0.004538276698440313, 0, -127, 127, torch.int8);  _frozen_param10 = None\n",
            "    conv2d_10 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_31, dequantize_per_tensor_default_32, None, [2, 2], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_31 = dequantize_per_tensor_default_32 = None\n",
            "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_10, 0.10224415361881256, -1, -128, 127, torch.int8);  conv2d_10 = None\n",
            "    dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.10224415361881256, -1, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
            "    _param_constant31 = self.features_4_conv_1_1_weight\n",
            "    _param_constant32 = self.features_4_conv_1_1_bias\n",
            "    _tensor_constant20 = self.features_4_conv_1_1_running_mean\n",
            "    _tensor_constant21 = self.features_4_conv_1_1_running_var\n",
            "    cudnn_batch_norm_10 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_33, _param_constant31, _param_constant32, _tensor_constant20, _tensor_constant21, False, 0.1, 1e-05);  dequantize_per_tensor_default_33 = _param_constant31 = _param_constant32 = _tensor_constant20 = _tensor_constant21 = None\n",
            "    getitem_40 = cudnn_batch_norm_10[0];  cudnn_batch_norm_10 = None\n",
            "    hardtanh__7 = torch.ops.aten.hardtanh_.default(getitem_40, 0.0, 6.0);  getitem_40 = None\n",
            "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__7, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__7 = None\n",
            "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_34 = None\n",
            "    _frozen_param11 = self._frozen_param11\n",
            "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param11, 0.012214003130793571, 0, -127, 127, torch.int8);  _frozen_param11 = None\n",
            "    conv2d_11 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_34, dequantize_per_tensor_default_35);  dequantize_per_tensor_default_34 = dequantize_per_tensor_default_35 = None\n",
            "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_11, 0.15272167325019836, 7, -128, 127, torch.int8);  conv2d_11 = None\n",
            "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.15272167325019836, 7, -128, 127, torch.int8);  quantize_per_tensor_default_36 = None\n",
            "    _param_constant34 = self.features_4_conv_3_weight\n",
            "    _param_constant35 = self.features_4_conv_3_bias\n",
            "    _tensor_constant22 = self.features_4_conv_3_running_mean\n",
            "    _tensor_constant23 = self.features_4_conv_3_running_var\n",
            "    cudnn_batch_norm_11 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_36, _param_constant34, _param_constant35, _tensor_constant22, _tensor_constant23, False, 0.1, 1e-05);  dequantize_per_tensor_default_36 = _param_constant34 = _param_constant35 = _tensor_constant22 = _tensor_constant23 = None\n",
            "    getitem_44 = cudnn_batch_norm_11[0];  cudnn_batch_norm_11 = None\n",
            "    quantize_per_tensor_default_37 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_44, 0.21381711959838867, 4, -128, 127, torch.int8);  getitem_44 = None\n",
            "    dequantize_per_tensor_default_175 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.21381711959838867, 4, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_174 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.21381711959838867, 4, -128, 127, torch.int8);  quantize_per_tensor_default_37 = None\n",
            "    _frozen_param12 = self._frozen_param12\n",
            "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param12, 0.009760905057191849, 0, -127, 127, torch.int8);  _frozen_param12 = None\n",
            "    conv2d_12 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_174, dequantize_per_tensor_default_38);  dequantize_per_tensor_default_174 = dequantize_per_tensor_default_38 = None\n",
            "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 0.24944953620433807, -9, -128, 127, torch.int8);  conv2d_12 = None\n",
            "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.24944953620433807, -9, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
            "    _param_constant37 = self.features_5_conv_0_1_weight\n",
            "    _param_constant38 = self.features_5_conv_0_1_bias\n",
            "    _tensor_constant24 = self.features_5_conv_0_1_running_mean\n",
            "    _tensor_constant25 = self.features_5_conv_0_1_running_var\n",
            "    cudnn_batch_norm_12 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_39, _param_constant37, _param_constant38, _tensor_constant24, _tensor_constant25, False, 0.1, 1e-05);  dequantize_per_tensor_default_39 = _param_constant37 = _param_constant38 = _tensor_constant24 = _tensor_constant25 = None\n",
            "    getitem_48 = cudnn_batch_norm_12[0];  cudnn_batch_norm_12 = None\n",
            "    hardtanh__8 = torch.ops.aten.hardtanh_.default(getitem_48, 0.0, 6.0);  getitem_48 = None\n",
            "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__8, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__8 = None\n",
            "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_40 = None\n",
            "    _frozen_param13 = self._frozen_param13\n",
            "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param13, 0.00924244336783886, 0, -127, 127, torch.int8);  _frozen_param13 = None\n",
            "    conv2d_13 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_40, dequantize_per_tensor_default_41, None, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_40 = dequantize_per_tensor_default_41 = None\n",
            "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_13, 0.043942905962467194, 24, -128, 127, torch.int8);  conv2d_13 = None\n",
            "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.043942905962467194, 24, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
            "    _param_constant40 = self.features_5_conv_1_1_weight\n",
            "    _param_constant41 = self.features_5_conv_1_1_bias\n",
            "    _tensor_constant26 = self.features_5_conv_1_1_running_mean\n",
            "    _tensor_constant27 = self.features_5_conv_1_1_running_var\n",
            "    cudnn_batch_norm_13 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_42, _param_constant40, _param_constant41, _tensor_constant26, _tensor_constant27, False, 0.1, 1e-05);  dequantize_per_tensor_default_42 = _param_constant40 = _param_constant41 = _tensor_constant26 = _tensor_constant27 = None\n",
            "    getitem_52 = cudnn_batch_norm_13[0];  cudnn_batch_norm_13 = None\n",
            "    hardtanh__9 = torch.ops.aten.hardtanh_.default(getitem_52, 0.0, 6.0);  getitem_52 = None\n",
            "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__9, 0.023092832416296005, -128, -128, 127, torch.int8);  hardtanh__9 = None\n",
            "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.023092832416296005, -128, -128, 127, torch.int8);  quantize_per_tensor_default_43 = None\n",
            "    _frozen_param14 = self._frozen_param14\n",
            "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param14, 0.008687574416399002, 0, -127, 127, torch.int8);  _frozen_param14 = None\n",
            "    conv2d_14 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_43, dequantize_per_tensor_default_44);  dequantize_per_tensor_default_43 = dequantize_per_tensor_default_44 = None\n",
            "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_14, 0.09516923874616623, -5, -128, 127, torch.int8);  conv2d_14 = None\n",
            "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 0.09516923874616623, -5, -128, 127, torch.int8);  quantize_per_tensor_default_45 = None\n",
            "    _param_constant43 = self.features_5_conv_3_weight\n",
            "    _param_constant44 = self.features_5_conv_3_bias\n",
            "    _tensor_constant28 = self.features_5_conv_3_running_mean\n",
            "    _tensor_constant29 = self.features_5_conv_3_running_var\n",
            "    cudnn_batch_norm_14 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_45, _param_constant43, _param_constant44, _tensor_constant28, _tensor_constant29, False, 0.1, 1e-05);  dequantize_per_tensor_default_45 = _param_constant43 = _param_constant44 = _tensor_constant28 = _tensor_constant29 = None\n",
            "    getitem_56 = cudnn_batch_norm_14[0];  cudnn_batch_norm_14 = None\n",
            "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_56, 0.2066364586353302, 18, -128, 127, torch.int8);  getitem_56 = None\n",
            "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.2066364586353302, 18, -128, 127, torch.int8);  quantize_per_tensor_default_46 = None\n",
            "    add_1 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_175, dequantize_per_tensor_default_46);  dequantize_per_tensor_default_175 = dequantize_per_tensor_default_46 = None\n",
            "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_1, 0.2734636664390564, 4, -128, 127, torch.int8);  add_1 = None\n",
            "    dequantize_per_tensor_default_177 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.2734636664390564, 4, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_176 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.2734636664390564, 4, -128, 127, torch.int8);  quantize_per_tensor_default_47 = None\n",
            "    _frozen_param15 = self._frozen_param15\n",
            "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param15, 0.007733475882560015, 0, -127, 127, torch.int8);  _frozen_param15 = None\n",
            "    conv2d_15 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_176, dequantize_per_tensor_default_48);  dequantize_per_tensor_default_176 = dequantize_per_tensor_default_48 = None\n",
            "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_15, 0.32544979453086853, 6, -128, 127, torch.int8);  conv2d_15 = None\n",
            "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.32544979453086853, 6, -128, 127, torch.int8);  quantize_per_tensor_default_49 = None\n",
            "    _param_constant46 = self.features_6_conv_0_1_weight\n",
            "    _param_constant47 = self.features_6_conv_0_1_bias\n",
            "    _tensor_constant30 = self.features_6_conv_0_1_running_mean\n",
            "    _tensor_constant31 = self.features_6_conv_0_1_running_var\n",
            "    cudnn_batch_norm_15 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_49, _param_constant46, _param_constant47, _tensor_constant30, _tensor_constant31, False, 0.1, 1e-05);  dequantize_per_tensor_default_49 = _param_constant46 = _param_constant47 = _tensor_constant30 = _tensor_constant31 = None\n",
            "    getitem_60 = cudnn_batch_norm_15[0];  cudnn_batch_norm_15 = None\n",
            "    hardtanh__10 = torch.ops.aten.hardtanh_.default(getitem_60, 0.0, 6.0);  getitem_60 = None\n",
            "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__10, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__10 = None\n",
            "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_50 = None\n",
            "    _frozen_param16 = self._frozen_param16\n",
            "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param16, 0.007519140839576721, 0, -127, 127, torch.int8);  _frozen_param16 = None\n",
            "    conv2d_16 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_50, dequantize_per_tensor_default_51, None, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_50 = dequantize_per_tensor_default_51 = None\n",
            "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_16, 0.04219915345311165, 26, -128, 127, torch.int8);  conv2d_16 = None\n",
            "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.04219915345311165, 26, -128, 127, torch.int8);  quantize_per_tensor_default_52 = None\n",
            "    _param_constant49 = self.features_6_conv_1_1_weight\n",
            "    _param_constant50 = self.features_6_conv_1_1_bias\n",
            "    _tensor_constant32 = self.features_6_conv_1_1_running_mean\n",
            "    _tensor_constant33 = self.features_6_conv_1_1_running_var\n",
            "    cudnn_batch_norm_16 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_52, _param_constant49, _param_constant50, _tensor_constant32, _tensor_constant33, False, 0.1, 1e-05);  dequantize_per_tensor_default_52 = _param_constant49 = _param_constant50 = _tensor_constant32 = _tensor_constant33 = None\n",
            "    getitem_64 = cudnn_batch_norm_16[0];  cudnn_batch_norm_16 = None\n",
            "    hardtanh__11 = torch.ops.aten.hardtanh_.default(getitem_64, 0.0, 6.0);  getitem_64 = None\n",
            "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__11, 0.02347196824848652, -128, -128, 127, torch.int8);  hardtanh__11 = None\n",
            "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 0.02347196824848652, -128, -128, 127, torch.int8);  quantize_per_tensor_default_53 = None\n",
            "    _frozen_param17 = self._frozen_param17\n",
            "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param17, 0.00937547069042921, 0, -127, 127, torch.int8);  _frozen_param17 = None\n",
            "    conv2d_17 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_53, dequantize_per_tensor_default_54);  dequantize_per_tensor_default_53 = dequantize_per_tensor_default_54 = None\n",
            "    quantize_per_tensor_default_55 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 0.09199368953704834, -25, -128, 127, torch.int8);  conv2d_17 = None\n",
            "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.09199368953704834, -25, -128, 127, torch.int8);  quantize_per_tensor_default_55 = None\n",
            "    _param_constant52 = self.features_6_conv_3_weight\n",
            "    _param_constant53 = self.features_6_conv_3_bias\n",
            "    _tensor_constant34 = self.features_6_conv_3_running_mean\n",
            "    _tensor_constant35 = self.features_6_conv_3_running_var\n",
            "    cudnn_batch_norm_17 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_55, _param_constant52, _param_constant53, _tensor_constant34, _tensor_constant35, False, 0.1, 1e-05);  dequantize_per_tensor_default_55 = _param_constant52 = _param_constant53 = _tensor_constant34 = _tensor_constant35 = None\n",
            "    getitem_68 = cudnn_batch_norm_17[0];  cudnn_batch_norm_17 = None\n",
            "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_68, 0.27405378222465515, 12, -128, 127, torch.int8);  getitem_68 = None\n",
            "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 0.27405378222465515, 12, -128, 127, torch.int8);  quantize_per_tensor_default_56 = None\n",
            "    add_2 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_177, dequantize_per_tensor_default_56);  dequantize_per_tensor_default_177 = dequantize_per_tensor_default_56 = None\n",
            "    quantize_per_tensor_default_57 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_2, 0.33424121141433716, -4, -128, 127, torch.int8);  add_2 = None\n",
            "    dequantize_per_tensor_default_57 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_57, 0.33424121141433716, -4, -128, 127, torch.int8);  quantize_per_tensor_default_57 = None\n",
            "    _frozen_param18 = self._frozen_param18\n",
            "    dequantize_per_tensor_default_58 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param18, 0.011357514187693596, 0, -127, 127, torch.int8);  _frozen_param18 = None\n",
            "    conv2d_18 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_57, dequantize_per_tensor_default_58);  dequantize_per_tensor_default_57 = dequantize_per_tensor_default_58 = None\n",
            "    quantize_per_tensor_default_59 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_18, 0.4297846555709839, -1, -128, 127, torch.int8);  conv2d_18 = None\n",
            "    dequantize_per_tensor_default_59 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_59, 0.4297846555709839, -1, -128, 127, torch.int8);  quantize_per_tensor_default_59 = None\n",
            "    _param_constant55 = self.features_7_conv_0_1_weight\n",
            "    _param_constant56 = self.features_7_conv_0_1_bias\n",
            "    _tensor_constant36 = self.features_7_conv_0_1_running_mean\n",
            "    _tensor_constant37 = self.features_7_conv_0_1_running_var\n",
            "    cudnn_batch_norm_18 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_59, _param_constant55, _param_constant56, _tensor_constant36, _tensor_constant37, False, 0.1, 1e-05);  dequantize_per_tensor_default_59 = _param_constant55 = _param_constant56 = _tensor_constant36 = _tensor_constant37 = None\n",
            "    getitem_72 = cudnn_batch_norm_18[0];  cudnn_batch_norm_18 = None\n",
            "    hardtanh__12 = torch.ops.aten.hardtanh_.default(getitem_72, 0.0, 6.0);  getitem_72 = None\n",
            "    quantize_per_tensor_default_60 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__12, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__12 = None\n",
            "    dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_60, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_60 = None\n",
            "    _frozen_param19 = self._frozen_param19\n",
            "    dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param19, 0.004068911075592041, 0, -127, 127, torch.int8);  _frozen_param19 = None\n",
            "    conv2d_19 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_60, dequantize_per_tensor_default_61, None, [2, 2], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_60 = dequantize_per_tensor_default_61 = None\n",
            "    quantize_per_tensor_default_62 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 0.07016446441411972, 22, -128, 127, torch.int8);  conv2d_19 = None\n",
            "    dequantize_per_tensor_default_62 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_62, 0.07016446441411972, 22, -128, 127, torch.int8);  quantize_per_tensor_default_62 = None\n",
            "    _param_constant58 = self.features_7_conv_1_1_weight\n",
            "    _param_constant59 = self.features_7_conv_1_1_bias\n",
            "    _tensor_constant38 = self.features_7_conv_1_1_running_mean\n",
            "    _tensor_constant39 = self.features_7_conv_1_1_running_var\n",
            "    cudnn_batch_norm_19 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_62, _param_constant58, _param_constant59, _tensor_constant38, _tensor_constant39, False, 0.1, 1e-05);  dequantize_per_tensor_default_62 = _param_constant58 = _param_constant59 = _tensor_constant38 = _tensor_constant39 = None\n",
            "    getitem_76 = cudnn_batch_norm_19[0];  cudnn_batch_norm_19 = None\n",
            "    hardtanh__13 = torch.ops.aten.hardtanh_.default(getitem_76, 0.0, 6.0);  getitem_76 = None\n",
            "    quantize_per_tensor_default_63 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__13, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__13 = None\n",
            "    dequantize_per_tensor_default_63 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_63, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_63 = None\n",
            "    _frozen_param20 = self._frozen_param20\n",
            "    dequantize_per_tensor_default_64 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param20, 0.01065182313323021, 0, -127, 127, torch.int8);  _frozen_param20 = None\n",
            "    conv2d_20 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_63, dequantize_per_tensor_default_64);  dequantize_per_tensor_default_63 = dequantize_per_tensor_default_64 = None\n",
            "    quantize_per_tensor_default_65 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_20, 0.2136654406785965, 5, -128, 127, torch.int8);  conv2d_20 = None\n",
            "    dequantize_per_tensor_default_65 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_65, 0.2136654406785965, 5, -128, 127, torch.int8);  quantize_per_tensor_default_65 = None\n",
            "    _param_constant61 = self.features_7_conv_3_weight\n",
            "    _param_constant62 = self.features_7_conv_3_bias\n",
            "    _tensor_constant40 = self.features_7_conv_3_running_mean\n",
            "    _tensor_constant41 = self.features_7_conv_3_running_var\n",
            "    cudnn_batch_norm_20 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_65, _param_constant61, _param_constant62, _tensor_constant40, _tensor_constant41, False, 0.1, 1e-05);  dequantize_per_tensor_default_65 = _param_constant61 = _param_constant62 = _tensor_constant40 = _tensor_constant41 = None\n",
            "    getitem_80 = cudnn_batch_norm_20[0];  cudnn_batch_norm_20 = None\n",
            "    quantize_per_tensor_default_66 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_80, 0.18607454001903534, 10, -128, 127, torch.int8);  getitem_80 = None\n",
            "    dequantize_per_tensor_default_179 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_66, 0.18607454001903534, 10, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_178 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_66, 0.18607454001903534, 10, -128, 127, torch.int8);  quantize_per_tensor_default_66 = None\n",
            "    _frozen_param21 = self._frozen_param21\n",
            "    dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param21, 0.006169645581394434, 0, -127, 127, torch.int8);  _frozen_param21 = None\n",
            "    conv2d_21 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_178, dequantize_per_tensor_default_67);  dequantize_per_tensor_default_178 = dequantize_per_tensor_default_67 = None\n",
            "    quantize_per_tensor_default_68 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_21, 0.25737684965133667, -1, -128, 127, torch.int8);  conv2d_21 = None\n",
            "    dequantize_per_tensor_default_68 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_68, 0.25737684965133667, -1, -128, 127, torch.int8);  quantize_per_tensor_default_68 = None\n",
            "    _param_constant64 = self.features_8_conv_0_1_weight\n",
            "    _param_constant65 = self.features_8_conv_0_1_bias\n",
            "    _tensor_constant42 = self.features_8_conv_0_1_running_mean\n",
            "    _tensor_constant43 = self.features_8_conv_0_1_running_var\n",
            "    cudnn_batch_norm_21 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_68, _param_constant64, _param_constant65, _tensor_constant42, _tensor_constant43, False, 0.1, 1e-05);  dequantize_per_tensor_default_68 = _param_constant64 = _param_constant65 = _tensor_constant42 = _tensor_constant43 = None\n",
            "    getitem_84 = cudnn_batch_norm_21[0];  cudnn_batch_norm_21 = None\n",
            "    hardtanh__14 = torch.ops.aten.hardtanh_.default(getitem_84, 0.0, 6.0);  getitem_84 = None\n",
            "    quantize_per_tensor_default_69 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__14, 0.02350643463432789, -128, -128, 127, torch.int8);  hardtanh__14 = None\n",
            "    dequantize_per_tensor_default_69 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_69, 0.02350643463432789, -128, -128, 127, torch.int8);  quantize_per_tensor_default_69 = None\n",
            "    _frozen_param22 = self._frozen_param22\n",
            "    dequantize_per_tensor_default_70 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param22, 0.006310861092060804, 0, -127, 127, torch.int8);  _frozen_param22 = None\n",
            "    conv2d_22 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_69, dequantize_per_tensor_default_70, None, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_69 = dequantize_per_tensor_default_70 = None\n",
            "    quantize_per_tensor_default_71 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_22, 0.04656070098280907, 18, -128, 127, torch.int8);  conv2d_22 = None\n",
            "    dequantize_per_tensor_default_71 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_71, 0.04656070098280907, 18, -128, 127, torch.int8);  quantize_per_tensor_default_71 = None\n",
            "    _param_constant67 = self.features_8_conv_1_1_weight\n",
            "    _param_constant68 = self.features_8_conv_1_1_bias\n",
            "    _tensor_constant44 = self.features_8_conv_1_1_running_mean\n",
            "    _tensor_constant45 = self.features_8_conv_1_1_running_var\n",
            "    cudnn_batch_norm_22 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_71, _param_constant67, _param_constant68, _tensor_constant44, _tensor_constant45, False, 0.1, 1e-05);  dequantize_per_tensor_default_71 = _param_constant67 = _param_constant68 = _tensor_constant44 = _tensor_constant45 = None\n",
            "    getitem_88 = cudnn_batch_norm_22[0];  cudnn_batch_norm_22 = None\n",
            "    hardtanh__15 = torch.ops.aten.hardtanh_.default(getitem_88, 0.0, 6.0);  getitem_88 = None\n",
            "    quantize_per_tensor_default_72 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__15, 0.023069854825735092, -128, -128, 127, torch.int8);  hardtanh__15 = None\n",
            "    dequantize_per_tensor_default_72 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_72, 0.023069854825735092, -128, -128, 127, torch.int8);  quantize_per_tensor_default_72 = None\n",
            "    _frozen_param23 = self._frozen_param23\n",
            "    dequantize_per_tensor_default_73 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param23, 0.0090605728328228, 0, -127, 127, torch.int8);  _frozen_param23 = None\n",
            "    conv2d_23 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_72, dequantize_per_tensor_default_73);  dequantize_per_tensor_default_72 = dequantize_per_tensor_default_73 = None\n",
            "    quantize_per_tensor_default_74 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_23, 0.10972335189580917, 18, -128, 127, torch.int8);  conv2d_23 = None\n",
            "    dequantize_per_tensor_default_74 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_74, 0.10972335189580917, 18, -128, 127, torch.int8);  quantize_per_tensor_default_74 = None\n",
            "    _param_constant70 = self.features_8_conv_3_weight\n",
            "    _param_constant71 = self.features_8_conv_3_bias\n",
            "    _tensor_constant46 = self.features_8_conv_3_running_mean\n",
            "    _tensor_constant47 = self.features_8_conv_3_running_var\n",
            "    cudnn_batch_norm_23 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_74, _param_constant70, _param_constant71, _tensor_constant46, _tensor_constant47, False, 0.1, 1e-05);  dequantize_per_tensor_default_74 = _param_constant70 = _param_constant71 = _tensor_constant46 = _tensor_constant47 = None\n",
            "    getitem_92 = cudnn_batch_norm_23[0];  cudnn_batch_norm_23 = None\n",
            "    quantize_per_tensor_default_75 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_92, 0.23782914876937866, 5, -128, 127, torch.int8);  getitem_92 = None\n",
            "    dequantize_per_tensor_default_75 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_75, 0.23782914876937866, 5, -128, 127, torch.int8);  quantize_per_tensor_default_75 = None\n",
            "    add_3 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_179, dequantize_per_tensor_default_75);  dequantize_per_tensor_default_179 = dequantize_per_tensor_default_75 = None\n",
            "    quantize_per_tensor_default_76 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_3, 0.21471011638641357, 5, -128, 127, torch.int8);  add_3 = None\n",
            "    dequantize_per_tensor_default_181 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_76, 0.21471011638641357, 5, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_180 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_76, 0.21471011638641357, 5, -128, 127, torch.int8);  quantize_per_tensor_default_76 = None\n",
            "    _frozen_param24 = self._frozen_param24\n",
            "    dequantize_per_tensor_default_77 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param24, 0.011715512722730637, 0, -127, 127, torch.int8);  _frozen_param24 = None\n",
            "    conv2d_24 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_180, dequantize_per_tensor_default_77);  dequantize_per_tensor_default_180 = dequantize_per_tensor_default_77 = None\n",
            "    quantize_per_tensor_default_78 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_24, 0.3233068287372589, 7, -128, 127, torch.int8);  conv2d_24 = None\n",
            "    dequantize_per_tensor_default_78 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_78, 0.3233068287372589, 7, -128, 127, torch.int8);  quantize_per_tensor_default_78 = None\n",
            "    _param_constant73 = self.features_9_conv_0_1_weight\n",
            "    _param_constant74 = self.features_9_conv_0_1_bias\n",
            "    _tensor_constant48 = self.features_9_conv_0_1_running_mean\n",
            "    _tensor_constant49 = self.features_9_conv_0_1_running_var\n",
            "    cudnn_batch_norm_24 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_78, _param_constant73, _param_constant74, _tensor_constant48, _tensor_constant49, False, 0.1, 1e-05);  dequantize_per_tensor_default_78 = _param_constant73 = _param_constant74 = _tensor_constant48 = _tensor_constant49 = None\n",
            "    getitem_96 = cudnn_batch_norm_24[0];  cudnn_batch_norm_24 = None\n",
            "    hardtanh__16 = torch.ops.aten.hardtanh_.default(getitem_96, 0.0, 6.0);  getitem_96 = None\n",
            "    quantize_per_tensor_default_79 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__16, 0.023357078433036804, -128, -128, 127, torch.int8);  hardtanh__16 = None\n",
            "    dequantize_per_tensor_default_79 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.023357078433036804, -128, -128, 127, torch.int8);  quantize_per_tensor_default_79 = None\n",
            "    _frozen_param25 = self._frozen_param25\n",
            "    dequantize_per_tensor_default_80 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param25, 0.006404954940080643, 0, -127, 127, torch.int8);  _frozen_param25 = None\n",
            "    conv2d_25 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_79, dequantize_per_tensor_default_80, None, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_79 = dequantize_per_tensor_default_80 = None\n",
            "    quantize_per_tensor_default_81 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_25, 0.03834123909473419, 20, -128, 127, torch.int8);  conv2d_25 = None\n",
            "    dequantize_per_tensor_default_81 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_81, 0.03834123909473419, 20, -128, 127, torch.int8);  quantize_per_tensor_default_81 = None\n",
            "    _param_constant76 = self.features_9_conv_1_1_weight\n",
            "    _param_constant77 = self.features_9_conv_1_1_bias\n",
            "    _tensor_constant50 = self.features_9_conv_1_1_running_mean\n",
            "    _tensor_constant51 = self.features_9_conv_1_1_running_var\n",
            "    cudnn_batch_norm_25 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_81, _param_constant76, _param_constant77, _tensor_constant50, _tensor_constant51, False, 0.1, 1e-05);  dequantize_per_tensor_default_81 = _param_constant76 = _param_constant77 = _tensor_constant50 = _tensor_constant51 = None\n",
            "    getitem_100 = cudnn_batch_norm_25[0];  cudnn_batch_norm_25 = None\n",
            "    hardtanh__17 = torch.ops.aten.hardtanh_.default(getitem_100, 0.0, 6.0);  getitem_100 = None\n",
            "    quantize_per_tensor_default_82 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__17, 0.022736674174666405, -128, -128, 127, torch.int8);  hardtanh__17 = None\n",
            "    dequantize_per_tensor_default_82 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_82, 0.022736674174666405, -128, -128, 127, torch.int8);  quantize_per_tensor_default_82 = None\n",
            "    _frozen_param26 = self._frozen_param26\n",
            "    dequantize_per_tensor_default_83 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param26, 0.010306141339242458, 0, -127, 127, torch.int8);  _frozen_param26 = None\n",
            "    conv2d_26 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_82, dequantize_per_tensor_default_83);  dequantize_per_tensor_default_82 = dequantize_per_tensor_default_83 = None\n",
            "    quantize_per_tensor_default_84 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_26, 0.10544487833976746, -18, -128, 127, torch.int8);  conv2d_26 = None\n",
            "    dequantize_per_tensor_default_84 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_84, 0.10544487833976746, -18, -128, 127, torch.int8);  quantize_per_tensor_default_84 = None\n",
            "    _param_constant79 = self.features_9_conv_3_weight\n",
            "    _param_constant80 = self.features_9_conv_3_bias\n",
            "    _tensor_constant52 = self.features_9_conv_3_running_mean\n",
            "    _tensor_constant53 = self.features_9_conv_3_running_var\n",
            "    cudnn_batch_norm_26 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_84, _param_constant79, _param_constant80, _tensor_constant52, _tensor_constant53, False, 0.1, 1e-05);  dequantize_per_tensor_default_84 = _param_constant79 = _param_constant80 = _tensor_constant52 = _tensor_constant53 = None\n",
            "    getitem_104 = cudnn_batch_norm_26[0];  cudnn_batch_norm_26 = None\n",
            "    quantize_per_tensor_default_85 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_104, 0.1518331617116928, -1, -128, 127, torch.int8);  getitem_104 = None\n",
            "    dequantize_per_tensor_default_85 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.1518331617116928, -1, -128, 127, torch.int8);  quantize_per_tensor_default_85 = None\n",
            "    add_4 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_181, dequantize_per_tensor_default_85);  dequantize_per_tensor_default_181 = dequantize_per_tensor_default_85 = None\n",
            "    quantize_per_tensor_default_86 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_4, 0.22389572858810425, 2, -128, 127, torch.int8);  add_4 = None\n",
            "    dequantize_per_tensor_default_183 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_86, 0.22389572858810425, 2, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_182 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_86, 0.22389572858810425, 2, -128, 127, torch.int8);  quantize_per_tensor_default_86 = None\n",
            "    _frozen_param27 = self._frozen_param27\n",
            "    dequantize_per_tensor_default_87 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param27, 0.008043158799409866, 0, -127, 127, torch.int8);  _frozen_param27 = None\n",
            "    conv2d_27 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_182, dequantize_per_tensor_default_87);  dequantize_per_tensor_default_182 = dequantize_per_tensor_default_87 = None\n",
            "    quantize_per_tensor_default_88 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_27, 0.3609669506549835, 9, -128, 127, torch.int8);  conv2d_27 = None\n",
            "    dequantize_per_tensor_default_88 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_88, 0.3609669506549835, 9, -128, 127, torch.int8);  quantize_per_tensor_default_88 = None\n",
            "    _param_constant82 = self.features_10_conv_0_1_weight\n",
            "    _param_constant83 = self.features_10_conv_0_1_bias\n",
            "    _tensor_constant54 = self.features_10_conv_0_1_running_mean\n",
            "    _tensor_constant55 = self.features_10_conv_0_1_running_var\n",
            "    cudnn_batch_norm_27 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_88, _param_constant82, _param_constant83, _tensor_constant54, _tensor_constant55, False, 0.1, 1e-05);  dequantize_per_tensor_default_88 = _param_constant82 = _param_constant83 = _tensor_constant54 = _tensor_constant55 = None\n",
            "    getitem_108 = cudnn_batch_norm_27[0];  cudnn_batch_norm_27 = None\n",
            "    hardtanh__18 = torch.ops.aten.hardtanh_.default(getitem_108, 0.0, 6.0);  getitem_108 = None\n",
            "    quantize_per_tensor_default_89 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__18, 0.021886490285396576, -128, -128, 127, torch.int8);  hardtanh__18 = None\n",
            "    dequantize_per_tensor_default_89 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_89, 0.021886490285396576, -128, -128, 127, torch.int8);  quantize_per_tensor_default_89 = None\n",
            "    _frozen_param28 = self._frozen_param28\n",
            "    dequantize_per_tensor_default_90 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param28, 0.008774113841354847, 0, -127, 127, torch.int8);  _frozen_param28 = None\n",
            "    conv2d_28 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_89, dequantize_per_tensor_default_90, None, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_89 = dequantize_per_tensor_default_90 = None\n",
            "    quantize_per_tensor_default_91 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_28, 0.03660385683178902, 1, -128, 127, torch.int8);  conv2d_28 = None\n",
            "    dequantize_per_tensor_default_91 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.03660385683178902, 1, -128, 127, torch.int8);  quantize_per_tensor_default_91 = None\n",
            "    _param_constant85 = self.features_10_conv_1_1_weight\n",
            "    _param_constant86 = self.features_10_conv_1_1_bias\n",
            "    _tensor_constant56 = self.features_10_conv_1_1_running_mean\n",
            "    _tensor_constant57 = self.features_10_conv_1_1_running_var\n",
            "    cudnn_batch_norm_28 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_91, _param_constant85, _param_constant86, _tensor_constant56, _tensor_constant57, False, 0.1, 1e-05);  dequantize_per_tensor_default_91 = _param_constant85 = _param_constant86 = _tensor_constant56 = _tensor_constant57 = None\n",
            "    getitem_112 = cudnn_batch_norm_28[0];  cudnn_batch_norm_28 = None\n",
            "    hardtanh__19 = torch.ops.aten.hardtanh_.default(getitem_112, 0.0, 6.0);  getitem_112 = None\n",
            "    quantize_per_tensor_default_92 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__19, 0.023127298802137375, -128, -128, 127, torch.int8);  hardtanh__19 = None\n",
            "    dequantize_per_tensor_default_92 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_92, 0.023127298802137375, -128, -128, 127, torch.int8);  quantize_per_tensor_default_92 = None\n",
            "    _frozen_param29 = self._frozen_param29\n",
            "    dequantize_per_tensor_default_93 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param29, 0.010140661150217056, 0, -127, 127, torch.int8);  _frozen_param29 = None\n",
            "    conv2d_29 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_92, dequantize_per_tensor_default_93);  dequantize_per_tensor_default_92 = dequantize_per_tensor_default_93 = None\n",
            "    quantize_per_tensor_default_94 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_29, 0.07005250453948975, -1, -128, 127, torch.int8);  conv2d_29 = None\n",
            "    dequantize_per_tensor_default_94 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_94, 0.07005250453948975, -1, -128, 127, torch.int8);  quantize_per_tensor_default_94 = None\n",
            "    _param_constant88 = self.features_10_conv_3_weight\n",
            "    _param_constant89 = self.features_10_conv_3_bias\n",
            "    _tensor_constant58 = self.features_10_conv_3_running_mean\n",
            "    _tensor_constant59 = self.features_10_conv_3_running_var\n",
            "    cudnn_batch_norm_29 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_94, _param_constant88, _param_constant89, _tensor_constant58, _tensor_constant59, False, 0.1, 1e-05);  dequantize_per_tensor_default_94 = _param_constant88 = _param_constant89 = _tensor_constant58 = _tensor_constant59 = None\n",
            "    getitem_116 = cudnn_batch_norm_29[0];  cudnn_batch_norm_29 = None\n",
            "    quantize_per_tensor_default_95 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_116, 0.2158910036087036, -6, -128, 127, torch.int8);  getitem_116 = None\n",
            "    dequantize_per_tensor_default_95 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_95, 0.2158910036087036, -6, -128, 127, torch.int8);  quantize_per_tensor_default_95 = None\n",
            "    add_5 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_183, dequantize_per_tensor_default_95);  dequantize_per_tensor_default_183 = dequantize_per_tensor_default_95 = None\n",
            "    quantize_per_tensor_default_96 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_5, 0.2597655951976776, -4, -128, 127, torch.int8);  add_5 = None\n",
            "    dequantize_per_tensor_default_96 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_96, 0.2597655951976776, -4, -128, 127, torch.int8);  quantize_per_tensor_default_96 = None\n",
            "    _frozen_param30 = self._frozen_param30\n",
            "    dequantize_per_tensor_default_97 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param30, 0.010844259522855282, 0, -127, 127, torch.int8);  _frozen_param30 = None\n",
            "    conv2d_30 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_96, dequantize_per_tensor_default_97);  dequantize_per_tensor_default_96 = dequantize_per_tensor_default_97 = None\n",
            "    quantize_per_tensor_default_98 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_30, 0.4061897397041321, -3, -128, 127, torch.int8);  conv2d_30 = None\n",
            "    dequantize_per_tensor_default_98 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_98, 0.4061897397041321, -3, -128, 127, torch.int8);  quantize_per_tensor_default_98 = None\n",
            "    _param_constant91 = self.features_11_conv_0_1_weight\n",
            "    _param_constant92 = self.features_11_conv_0_1_bias\n",
            "    _tensor_constant60 = self.features_11_conv_0_1_running_mean\n",
            "    _tensor_constant61 = self.features_11_conv_0_1_running_var\n",
            "    cudnn_batch_norm_30 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_98, _param_constant91, _param_constant92, _tensor_constant60, _tensor_constant61, False, 0.1, 1e-05);  dequantize_per_tensor_default_98 = _param_constant91 = _param_constant92 = _tensor_constant60 = _tensor_constant61 = None\n",
            "    getitem_120 = cudnn_batch_norm_30[0];  cudnn_batch_norm_30 = None\n",
            "    hardtanh__20 = torch.ops.aten.hardtanh_.default(getitem_120, 0.0, 6.0);  getitem_120 = None\n",
            "    quantize_per_tensor_default_99 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__20, 0.023483457043766975, -128, -128, 127, torch.int8);  hardtanh__20 = None\n",
            "    dequantize_per_tensor_default_99 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_99, 0.023483457043766975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_99 = None\n",
            "    _frozen_param31 = self._frozen_param31\n",
            "    dequantize_per_tensor_default_100 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param31, 0.007974155247211456, 0, -127, 127, torch.int8);  _frozen_param31 = None\n",
            "    conv2d_31 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_99, dequantize_per_tensor_default_100, None, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_99 = dequantize_per_tensor_default_100 = None\n",
            "    quantize_per_tensor_default_101 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_31, 0.054663579910993576, 14, -128, 127, torch.int8);  conv2d_31 = None\n",
            "    dequantize_per_tensor_default_101 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_101, 0.054663579910993576, 14, -128, 127, torch.int8);  quantize_per_tensor_default_101 = None\n",
            "    _param_constant94 = self.features_11_conv_1_1_weight\n",
            "    _param_constant95 = self.features_11_conv_1_1_bias\n",
            "    _tensor_constant62 = self.features_11_conv_1_1_running_mean\n",
            "    _tensor_constant63 = self.features_11_conv_1_1_running_var\n",
            "    cudnn_batch_norm_31 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_101, _param_constant94, _param_constant95, _tensor_constant62, _tensor_constant63, False, 0.1, 1e-05);  dequantize_per_tensor_default_101 = _param_constant94 = _param_constant95 = _tensor_constant62 = _tensor_constant63 = None\n",
            "    getitem_124 = cudnn_batch_norm_31[0];  cudnn_batch_norm_31 = None\n",
            "    hardtanh__21 = torch.ops.aten.hardtanh_.default(getitem_124, 0.0, 6.0);  getitem_124 = None\n",
            "    quantize_per_tensor_default_102 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__21, 0.02350643463432789, -128, -128, 127, torch.int8);  hardtanh__21 = None\n",
            "    dequantize_per_tensor_default_102 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_102, 0.02350643463432789, -128, -128, 127, torch.int8);  quantize_per_tensor_default_102 = None\n",
            "    _frozen_param32 = self._frozen_param32\n",
            "    dequantize_per_tensor_default_103 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param32, 0.0070518674328923225, 0, -127, 127, torch.int8);  _frozen_param32 = None\n",
            "    conv2d_32 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_102, dequantize_per_tensor_default_103);  dequantize_per_tensor_default_102 = dequantize_per_tensor_default_103 = None\n",
            "    quantize_per_tensor_default_104 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_32, 0.17635783553123474, -15, -128, 127, torch.int8);  conv2d_32 = None\n",
            "    dequantize_per_tensor_default_104 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_104, 0.17635783553123474, -15, -128, 127, torch.int8);  quantize_per_tensor_default_104 = None\n",
            "    _param_constant97 = self.features_11_conv_3_weight\n",
            "    _param_constant98 = self.features_11_conv_3_bias\n",
            "    _tensor_constant64 = self.features_11_conv_3_running_mean\n",
            "    _tensor_constant65 = self.features_11_conv_3_running_var\n",
            "    cudnn_batch_norm_32 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_104, _param_constant97, _param_constant98, _tensor_constant64, _tensor_constant65, False, 0.1, 1e-05);  dequantize_per_tensor_default_104 = _param_constant97 = _param_constant98 = _tensor_constant64 = _tensor_constant65 = None\n",
            "    getitem_128 = cudnn_batch_norm_32[0];  cudnn_batch_norm_32 = None\n",
            "    quantize_per_tensor_default_105 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_128, 0.16676466166973114, -1, -128, 127, torch.int8);  getitem_128 = None\n",
            "    dequantize_per_tensor_default_185 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_105, 0.16676466166973114, -1, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_184 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_105, 0.16676466166973114, -1, -128, 127, torch.int8);  quantize_per_tensor_default_105 = None\n",
            "    _frozen_param33 = self._frozen_param33\n",
            "    dequantize_per_tensor_default_106 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param33, 0.006214863155037165, 0, -127, 127, torch.int8);  _frozen_param33 = None\n",
            "    conv2d_33 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_184, dequantize_per_tensor_default_106);  dequantize_per_tensor_default_184 = dequantize_per_tensor_default_106 = None\n",
            "    quantize_per_tensor_default_107 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_33, 0.2813851833343506, -4, -128, 127, torch.int8);  conv2d_33 = None\n",
            "    dequantize_per_tensor_default_107 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_107, 0.2813851833343506, -4, -128, 127, torch.int8);  quantize_per_tensor_default_107 = None\n",
            "    _param_constant100 = self.features_12_conv_0_1_weight\n",
            "    _param_constant101 = self.features_12_conv_0_1_bias\n",
            "    _tensor_constant66 = self.features_12_conv_0_1_running_mean\n",
            "    _tensor_constant67 = self.features_12_conv_0_1_running_var\n",
            "    cudnn_batch_norm_33 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_107, _param_constant100, _param_constant101, _tensor_constant66, _tensor_constant67, False, 0.1, 1e-05);  dequantize_per_tensor_default_107 = _param_constant100 = _param_constant101 = _tensor_constant66 = _tensor_constant67 = None\n",
            "    getitem_132 = cudnn_batch_norm_33[0];  cudnn_batch_norm_33 = None\n",
            "    hardtanh__22 = torch.ops.aten.hardtanh_.default(getitem_132, 0.0, 6.0);  getitem_132 = None\n",
            "    quantize_per_tensor_default_108 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__22, 0.023448990657925606, -128, -128, 127, torch.int8);  hardtanh__22 = None\n",
            "    dequantize_per_tensor_default_108 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_108, 0.023448990657925606, -128, -128, 127, torch.int8);  quantize_per_tensor_default_108 = None\n",
            "    _frozen_param34 = self._frozen_param34\n",
            "    dequantize_per_tensor_default_109 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param34, 0.00601201830431819, 0, -127, 127, torch.int8);  _frozen_param34 = None\n",
            "    conv2d_34 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_108, dequantize_per_tensor_default_109, None, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_108 = dequantize_per_tensor_default_109 = None\n",
            "    quantize_per_tensor_default_110 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_34, 0.034541137516498566, 2, -128, 127, torch.int8);  conv2d_34 = None\n",
            "    dequantize_per_tensor_default_110 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_110, 0.034541137516498566, 2, -128, 127, torch.int8);  quantize_per_tensor_default_110 = None\n",
            "    _param_constant103 = self.features_12_conv_1_1_weight\n",
            "    _param_constant104 = self.features_12_conv_1_1_bias\n",
            "    _tensor_constant68 = self.features_12_conv_1_1_running_mean\n",
            "    _tensor_constant69 = self.features_12_conv_1_1_running_var\n",
            "    cudnn_batch_norm_34 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_110, _param_constant103, _param_constant104, _tensor_constant68, _tensor_constant69, False, 0.1, 1e-05);  dequantize_per_tensor_default_110 = _param_constant103 = _param_constant104 = _tensor_constant68 = _tensor_constant69 = None\n",
            "    getitem_136 = cudnn_batch_norm_34[0];  cudnn_batch_norm_34 = None\n",
            "    hardtanh__23 = torch.ops.aten.hardtanh_.default(getitem_136, 0.0, 6.0);  getitem_136 = None\n",
            "    quantize_per_tensor_default_111 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__23, 0.023322612047195435, -128, -128, 127, torch.int8);  hardtanh__23 = None\n",
            "    dequantize_per_tensor_default_111 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_111, 0.023322612047195435, -128, -128, 127, torch.int8);  quantize_per_tensor_default_111 = None\n",
            "    _frozen_param35 = self._frozen_param35\n",
            "    dequantize_per_tensor_default_112 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param35, 0.006557791028171778, 0, -127, 127, torch.int8);  _frozen_param35 = None\n",
            "    conv2d_35 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_111, dequantize_per_tensor_default_112);  dequantize_per_tensor_default_111 = dequantize_per_tensor_default_112 = None\n",
            "    quantize_per_tensor_default_113 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_35, 0.09165257960557938, 2, -128, 127, torch.int8);  conv2d_35 = None\n",
            "    dequantize_per_tensor_default_113 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_113, 0.09165257960557938, 2, -128, 127, torch.int8);  quantize_per_tensor_default_113 = None\n",
            "    _param_constant106 = self.features_12_conv_3_weight\n",
            "    _param_constant107 = self.features_12_conv_3_bias\n",
            "    _tensor_constant70 = self.features_12_conv_3_running_mean\n",
            "    _tensor_constant71 = self.features_12_conv_3_running_var\n",
            "    cudnn_batch_norm_35 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_113, _param_constant106, _param_constant107, _tensor_constant70, _tensor_constant71, False, 0.1, 1e-05);  dequantize_per_tensor_default_113 = _param_constant106 = _param_constant107 = _tensor_constant70 = _tensor_constant71 = None\n",
            "    getitem_140 = cudnn_batch_norm_35[0];  cudnn_batch_norm_35 = None\n",
            "    quantize_per_tensor_default_114 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_140, 0.12511809170246124, -1, -128, 127, torch.int8);  getitem_140 = None\n",
            "    dequantize_per_tensor_default_114 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_114, 0.12511809170246124, -1, -128, 127, torch.int8);  quantize_per_tensor_default_114 = None\n",
            "    add_6 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_185, dequantize_per_tensor_default_114);  dequantize_per_tensor_default_185 = dequantize_per_tensor_default_114 = None\n",
            "    quantize_per_tensor_default_115 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_6, 0.18450190126895905, 1, -128, 127, torch.int8);  add_6 = None\n",
            "    dequantize_per_tensor_default_187 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_115, 0.18450190126895905, 1, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_186 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_115, 0.18450190126895905, 1, -128, 127, torch.int8);  quantize_per_tensor_default_115 = None\n",
            "    _frozen_param36 = self._frozen_param36\n",
            "    dequantize_per_tensor_default_116 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param36, 0.00620492547750473, 0, -127, 127, torch.int8);  _frozen_param36 = None\n",
            "    conv2d_36 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_186, dequantize_per_tensor_default_116);  dequantize_per_tensor_default_186 = dequantize_per_tensor_default_116 = None\n",
            "    quantize_per_tensor_default_117 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_36, 0.3263174295425415, 1, -128, 127, torch.int8);  conv2d_36 = None\n",
            "    dequantize_per_tensor_default_117 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_117, 0.3263174295425415, 1, -128, 127, torch.int8);  quantize_per_tensor_default_117 = None\n",
            "    _param_constant109 = self.features_13_conv_0_1_weight\n",
            "    _param_constant110 = self.features_13_conv_0_1_bias\n",
            "    _tensor_constant72 = self.features_13_conv_0_1_running_mean\n",
            "    _tensor_constant73 = self.features_13_conv_0_1_running_var\n",
            "    cudnn_batch_norm_36 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_117, _param_constant109, _param_constant110, _tensor_constant72, _tensor_constant73, False, 0.1, 1e-05);  dequantize_per_tensor_default_117 = _param_constant109 = _param_constant110 = _tensor_constant72 = _tensor_constant73 = None\n",
            "    getitem_144 = cudnn_batch_norm_36[0];  cudnn_batch_norm_36 = None\n",
            "    hardtanh__24 = torch.ops.aten.hardtanh_.default(getitem_144, 0.0, 6.0);  getitem_144 = None\n",
            "    quantize_per_tensor_default_118 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__24, 0.022667739540338516, -128, -128, 127, torch.int8);  hardtanh__24 = None\n",
            "    dequantize_per_tensor_default_118 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_118, 0.022667739540338516, -128, -128, 127, torch.int8);  quantize_per_tensor_default_118 = None\n",
            "    _frozen_param37 = self._frozen_param37\n",
            "    dequantize_per_tensor_default_119 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param37, 0.00605909526348114, 0, -127, 127, torch.int8);  _frozen_param37 = None\n",
            "    conv2d_37 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_118, dequantize_per_tensor_default_119, None, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_118 = dequantize_per_tensor_default_119 = None\n",
            "    quantize_per_tensor_default_120 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_37, 0.034727953374385834, -1, -128, 127, torch.int8);  conv2d_37 = None\n",
            "    dequantize_per_tensor_default_120 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_120, 0.034727953374385834, -1, -128, 127, torch.int8);  quantize_per_tensor_default_120 = None\n",
            "    _param_constant112 = self.features_13_conv_1_1_weight\n",
            "    _param_constant113 = self.features_13_conv_1_1_bias\n",
            "    _tensor_constant74 = self.features_13_conv_1_1_running_mean\n",
            "    _tensor_constant75 = self.features_13_conv_1_1_running_var\n",
            "    cudnn_batch_norm_37 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_120, _param_constant112, _param_constant113, _tensor_constant74, _tensor_constant75, False, 0.1, 1e-05);  dequantize_per_tensor_default_120 = _param_constant112 = _param_constant113 = _tensor_constant74 = _tensor_constant75 = None\n",
            "    getitem_148 = cudnn_batch_norm_37[0];  cudnn_batch_norm_37 = None\n",
            "    hardtanh__25 = torch.ops.aten.hardtanh_.default(getitem_148, 0.0, 6.0);  getitem_148 = None\n",
            "    quantize_per_tensor_default_121 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__25, 0.023161765187978745, -128, -128, 127, torch.int8);  hardtanh__25 = None\n",
            "    dequantize_per_tensor_default_121 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_121, 0.023161765187978745, -128, -128, 127, torch.int8);  quantize_per_tensor_default_121 = None\n",
            "    _frozen_param38 = self._frozen_param38\n",
            "    dequantize_per_tensor_default_122 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param38, 0.0049417950212955475, 0, -127, 127, torch.int8);  _frozen_param38 = None\n",
            "    conv2d_38 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_121, dequantize_per_tensor_default_122);  dequantize_per_tensor_default_121 = dequantize_per_tensor_default_122 = None\n",
            "    quantize_per_tensor_default_123 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_38, 0.12278582155704498, -19, -128, 127, torch.int8);  conv2d_38 = None\n",
            "    dequantize_per_tensor_default_123 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_123, 0.12278582155704498, -19, -128, 127, torch.int8);  quantize_per_tensor_default_123 = None\n",
            "    _param_constant115 = self.features_13_conv_3_weight\n",
            "    _param_constant116 = self.features_13_conv_3_bias\n",
            "    _tensor_constant76 = self.features_13_conv_3_running_mean\n",
            "    _tensor_constant77 = self.features_13_conv_3_running_var\n",
            "    cudnn_batch_norm_38 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_123, _param_constant115, _param_constant116, _tensor_constant76, _tensor_constant77, False, 0.1, 1e-05);  dequantize_per_tensor_default_123 = _param_constant115 = _param_constant116 = _tensor_constant76 = _tensor_constant77 = None\n",
            "    getitem_152 = cudnn_batch_norm_38[0];  cudnn_batch_norm_38 = None\n",
            "    quantize_per_tensor_default_124 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_152, 0.16980110108852386, 2, -128, 127, torch.int8);  getitem_152 = None\n",
            "    dequantize_per_tensor_default_124 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_124, 0.16980110108852386, 2, -128, 127, torch.int8);  quantize_per_tensor_default_124 = None\n",
            "    add_7 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_187, dequantize_per_tensor_default_124);  dequantize_per_tensor_default_187 = dequantize_per_tensor_default_124 = None\n",
            "    quantize_per_tensor_default_125 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_7, 0.23270462453365326, -3, -128, 127, torch.int8);  add_7 = None\n",
            "    dequantize_per_tensor_default_125 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 0.23270462453365326, -3, -128, 127, torch.int8);  quantize_per_tensor_default_125 = None\n",
            "    _frozen_param39 = self._frozen_param39\n",
            "    dequantize_per_tensor_default_126 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param39, 0.008780875243246555, 0, -127, 127, torch.int8);  _frozen_param39 = None\n",
            "    conv2d_39 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_125, dequantize_per_tensor_default_126);  dequantize_per_tensor_default_125 = dequantize_per_tensor_default_126 = None\n",
            "    quantize_per_tensor_default_127 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_39, 0.46609458327293396, -4, -128, 127, torch.int8);  conv2d_39 = None\n",
            "    dequantize_per_tensor_default_127 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_127, 0.46609458327293396, -4, -128, 127, torch.int8);  quantize_per_tensor_default_127 = None\n",
            "    _param_constant118 = self.features_14_conv_0_1_weight\n",
            "    _param_constant119 = self.features_14_conv_0_1_bias\n",
            "    _tensor_constant78 = self.features_14_conv_0_1_running_mean\n",
            "    _tensor_constant79 = self.features_14_conv_0_1_running_var\n",
            "    cudnn_batch_norm_39 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_127, _param_constant118, _param_constant119, _tensor_constant78, _tensor_constant79, False, 0.1, 1e-05);  dequantize_per_tensor_default_127 = _param_constant118 = _param_constant119 = _tensor_constant78 = _tensor_constant79 = None\n",
            "    getitem_156 = cudnn_batch_norm_39[0];  cudnn_batch_norm_39 = None\n",
            "    hardtanh__26 = torch.ops.aten.hardtanh_.default(getitem_156, 0.0, 6.0);  getitem_156 = None\n",
            "    quantize_per_tensor_default_128 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__26, 0.02320772223174572, -128, -128, 127, torch.int8);  hardtanh__26 = None\n",
            "    dequantize_per_tensor_default_128 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_128, 0.02320772223174572, -128, -128, 127, torch.int8);  quantize_per_tensor_default_128 = None\n",
            "    _frozen_param40 = self._frozen_param40\n",
            "    dequantize_per_tensor_default_129 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param40, 0.005532474257051945, 0, -127, 127, torch.int8);  _frozen_param40 = None\n",
            "    conv2d_40 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_128, dequantize_per_tensor_default_129, None, [2, 2], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_128 = dequantize_per_tensor_default_129 = None\n",
            "    quantize_per_tensor_default_130 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_40, 0.0678623765707016, 65, -128, 127, torch.int8);  conv2d_40 = None\n",
            "    dequantize_per_tensor_default_130 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_130, 0.0678623765707016, 65, -128, 127, torch.int8);  quantize_per_tensor_default_130 = None\n",
            "    _param_constant121 = self.features_14_conv_1_1_weight\n",
            "    _param_constant122 = self.features_14_conv_1_1_bias\n",
            "    _tensor_constant80 = self.features_14_conv_1_1_running_mean\n",
            "    _tensor_constant81 = self.features_14_conv_1_1_running_var\n",
            "    cudnn_batch_norm_40 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_130, _param_constant121, _param_constant122, _tensor_constant80, _tensor_constant81, False, 0.1, 1e-05);  dequantize_per_tensor_default_130 = _param_constant121 = _param_constant122 = _tensor_constant80 = _tensor_constant81 = None\n",
            "    getitem_160 = cudnn_batch_norm_40[0];  cudnn_batch_norm_40 = None\n",
            "    hardtanh__27 = torch.ops.aten.hardtanh_.default(getitem_160, 0.0, 6.0);  getitem_160 = None\n",
            "    quantize_per_tensor_default_131 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__27, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__27 = None\n",
            "    dequantize_per_tensor_default_131 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_131 = None\n",
            "    _frozen_param41 = self._frozen_param41\n",
            "    dequantize_per_tensor_default_132 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param41, 0.008911262266337872, 0, -127, 127, torch.int8);  _frozen_param41 = None\n",
            "    conv2d_41 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_131, dequantize_per_tensor_default_132);  dequantize_per_tensor_default_131 = dequantize_per_tensor_default_132 = None\n",
            "    quantize_per_tensor_default_133 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_41, 0.21288537979125977, 2, -128, 127, torch.int8);  conv2d_41 = None\n",
            "    dequantize_per_tensor_default_133 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_133, 0.21288537979125977, 2, -128, 127, torch.int8);  quantize_per_tensor_default_133 = None\n",
            "    _param_constant124 = self.features_14_conv_3_weight\n",
            "    _param_constant125 = self.features_14_conv_3_bias\n",
            "    _tensor_constant82 = self.features_14_conv_3_running_mean\n",
            "    _tensor_constant83 = self.features_14_conv_3_running_var\n",
            "    cudnn_batch_norm_41 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_133, _param_constant124, _param_constant125, _tensor_constant82, _tensor_constant83, False, 0.1, 1e-05);  dequantize_per_tensor_default_133 = _param_constant124 = _param_constant125 = _tensor_constant82 = _tensor_constant83 = None\n",
            "    getitem_164 = cudnn_batch_norm_41[0];  cudnn_batch_norm_41 = None\n",
            "    quantize_per_tensor_default_134 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_164, 0.14858853816986084, -4, -128, 127, torch.int8);  getitem_164 = None\n",
            "    dequantize_per_tensor_default_189 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_134, 0.14858853816986084, -4, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_188 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_134, 0.14858853816986084, -4, -128, 127, torch.int8);  quantize_per_tensor_default_134 = None\n",
            "    _frozen_param42 = self._frozen_param42\n",
            "    dequantize_per_tensor_default_135 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param42, 0.00630077812820673, 0, -127, 127, torch.int8);  _frozen_param42 = None\n",
            "    conv2d_42 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_188, dequantize_per_tensor_default_135);  dequantize_per_tensor_default_188 = dequantize_per_tensor_default_135 = None\n",
            "    quantize_per_tensor_default_136 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_42, 0.3083156645298004, -9, -128, 127, torch.int8);  conv2d_42 = None\n",
            "    dequantize_per_tensor_default_136 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_136, 0.3083156645298004, -9, -128, 127, torch.int8);  quantize_per_tensor_default_136 = None\n",
            "    _param_constant127 = self.features_15_conv_0_1_weight\n",
            "    _param_constant128 = self.features_15_conv_0_1_bias\n",
            "    _tensor_constant84 = self.features_15_conv_0_1_running_mean\n",
            "    _tensor_constant85 = self.features_15_conv_0_1_running_var\n",
            "    cudnn_batch_norm_42 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_136, _param_constant127, _param_constant128, _tensor_constant84, _tensor_constant85, False, 0.1, 1e-05);  dequantize_per_tensor_default_136 = _param_constant127 = _param_constant128 = _tensor_constant84 = _tensor_constant85 = None\n",
            "    getitem_168 = cudnn_batch_norm_42[0];  cudnn_batch_norm_42 = None\n",
            "    hardtanh__28 = torch.ops.aten.hardtanh_.default(getitem_168, 0.0, 6.0);  getitem_168 = None\n",
            "    quantize_per_tensor_default_137 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__28, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__28 = None\n",
            "    dequantize_per_tensor_default_137 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_137 = None\n",
            "    _frozen_param43 = self._frozen_param43\n",
            "    dequantize_per_tensor_default_138 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param43, 0.005665949080139399, 0, -127, 127, torch.int8);  _frozen_param43 = None\n",
            "    conv2d_43 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_137, dequantize_per_tensor_default_138, None, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_137 = dequantize_per_tensor_default_138 = None\n",
            "    quantize_per_tensor_default_139 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_43, 0.03768100589513779, 30, -128, 127, torch.int8);  conv2d_43 = None\n",
            "    dequantize_per_tensor_default_139 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_139, 0.03768100589513779, 30, -128, 127, torch.int8);  quantize_per_tensor_default_139 = None\n",
            "    _param_constant130 = self.features_15_conv_1_1_weight\n",
            "    _param_constant131 = self.features_15_conv_1_1_bias\n",
            "    _tensor_constant86 = self.features_15_conv_1_1_running_mean\n",
            "    _tensor_constant87 = self.features_15_conv_1_1_running_var\n",
            "    cudnn_batch_norm_43 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_139, _param_constant130, _param_constant131, _tensor_constant86, _tensor_constant87, False, 0.1, 1e-05);  dequantize_per_tensor_default_139 = _param_constant130 = _param_constant131 = _tensor_constant86 = _tensor_constant87 = None\n",
            "    getitem_172 = cudnn_batch_norm_43[0];  cudnn_batch_norm_43 = None\n",
            "    hardtanh__29 = torch.ops.aten.hardtanh_.default(getitem_172, 0.0, 6.0);  getitem_172 = None\n",
            "    quantize_per_tensor_default_140 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__29, 0.022633273154497147, -128, -128, 127, torch.int8);  hardtanh__29 = None\n",
            "    dequantize_per_tensor_default_140 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_140, 0.022633273154497147, -128, -128, 127, torch.int8);  quantize_per_tensor_default_140 = None\n",
            "    _frozen_param44 = self._frozen_param44\n",
            "    dequantize_per_tensor_default_141 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param44, 0.006148144602775574, 0, -127, 127, torch.int8);  _frozen_param44 = None\n",
            "    conv2d_44 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_140, dequantize_per_tensor_default_141);  dequantize_per_tensor_default_140 = dequantize_per_tensor_default_141 = None\n",
            "    quantize_per_tensor_default_142 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_44, 0.08964703977108002, -1, -128, 127, torch.int8);  conv2d_44 = None\n",
            "    dequantize_per_tensor_default_142 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_142, 0.08964703977108002, -1, -128, 127, torch.int8);  quantize_per_tensor_default_142 = None\n",
            "    _param_constant133 = self.features_15_conv_3_weight\n",
            "    _param_constant134 = self.features_15_conv_3_bias\n",
            "    _tensor_constant88 = self.features_15_conv_3_running_mean\n",
            "    _tensor_constant89 = self.features_15_conv_3_running_var\n",
            "    cudnn_batch_norm_44 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_142, _param_constant133, _param_constant134, _tensor_constant88, _tensor_constant89, False, 0.1, 1e-05);  dequantize_per_tensor_default_142 = _param_constant133 = _param_constant134 = _tensor_constant88 = _tensor_constant89 = None\n",
            "    getitem_176 = cudnn_batch_norm_44[0];  cudnn_batch_norm_44 = None\n",
            "    quantize_per_tensor_default_143 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_176, 0.13401825726032257, 4, -128, 127, torch.int8);  getitem_176 = None\n",
            "    dequantize_per_tensor_default_143 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 0.13401825726032257, 4, -128, 127, torch.int8);  quantize_per_tensor_default_143 = None\n",
            "    add_8 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_189, dequantize_per_tensor_default_143);  dequantize_per_tensor_default_189 = dequantize_per_tensor_default_143 = None\n",
            "    quantize_per_tensor_default_144 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_8, 0.15979422628879547, 1, -128, 127, torch.int8);  add_8 = None\n",
            "    dequantize_per_tensor_default_191 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_144, 0.15979422628879547, 1, -128, 127, torch.int8)\n",
            "    dequantize_per_tensor_default_190 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_144, 0.15979422628879547, 1, -128, 127, torch.int8);  quantize_per_tensor_default_144 = None\n",
            "    _frozen_param45 = self._frozen_param45\n",
            "    dequantize_per_tensor_default_145 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param45, 0.009841733612120152, 0, -127, 127, torch.int8);  _frozen_param45 = None\n",
            "    conv2d_45 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_190, dequantize_per_tensor_default_145);  dequantize_per_tensor_default_190 = dequantize_per_tensor_default_145 = None\n",
            "    quantize_per_tensor_default_146 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_45, 0.378499299287796, -7, -128, 127, torch.int8);  conv2d_45 = None\n",
            "    dequantize_per_tensor_default_146 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_146, 0.378499299287796, -7, -128, 127, torch.int8);  quantize_per_tensor_default_146 = None\n",
            "    _param_constant136 = self.features_16_conv_0_1_weight\n",
            "    _param_constant137 = self.features_16_conv_0_1_bias\n",
            "    _tensor_constant90 = self.features_16_conv_0_1_running_mean\n",
            "    _tensor_constant91 = self.features_16_conv_0_1_running_var\n",
            "    cudnn_batch_norm_45 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_146, _param_constant136, _param_constant137, _tensor_constant90, _tensor_constant91, False, 0.1, 1e-05);  dequantize_per_tensor_default_146 = _param_constant136 = _param_constant137 = _tensor_constant90 = _tensor_constant91 = None\n",
            "    getitem_180 = cudnn_batch_norm_45[0];  cudnn_batch_norm_45 = None\n",
            "    hardtanh__30 = torch.ops.aten.hardtanh_.default(getitem_180, 0.0, 6.0);  getitem_180 = None\n",
            "    quantize_per_tensor_default_147 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__30, 0.023448990657925606, -128, -128, 127, torch.int8);  hardtanh__30 = None\n",
            "    dequantize_per_tensor_default_147 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_147, 0.023448990657925606, -128, -128, 127, torch.int8);  quantize_per_tensor_default_147 = None\n",
            "    _frozen_param46 = self._frozen_param46\n",
            "    dequantize_per_tensor_default_148 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param46, 0.006306529510766268, 0, -127, 127, torch.int8);  _frozen_param46 = None\n",
            "    conv2d_46 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_147, dequantize_per_tensor_default_148, None, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_147 = dequantize_per_tensor_default_148 = None\n",
            "    quantize_per_tensor_default_149 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_46, 0.05297600105404854, 43, -128, 127, torch.int8);  conv2d_46 = None\n",
            "    dequantize_per_tensor_default_149 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 0.05297600105404854, 43, -128, 127, torch.int8);  quantize_per_tensor_default_149 = None\n",
            "    _param_constant139 = self.features_16_conv_1_1_weight\n",
            "    _param_constant140 = self.features_16_conv_1_1_bias\n",
            "    _tensor_constant92 = self.features_16_conv_1_1_running_mean\n",
            "    _tensor_constant93 = self.features_16_conv_1_1_running_var\n",
            "    cudnn_batch_norm_46 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_149, _param_constant139, _param_constant140, _tensor_constant92, _tensor_constant93, False, 0.1, 1e-05);  dequantize_per_tensor_default_149 = _param_constant139 = _param_constant140 = _tensor_constant92 = _tensor_constant93 = None\n",
            "    getitem_184 = cudnn_batch_norm_46[0];  cudnn_batch_norm_46 = None\n",
            "    hardtanh__31 = torch.ops.aten.hardtanh_.default(getitem_184, 0.0, 6.0);  getitem_184 = None\n",
            "    quantize_per_tensor_default_150 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__31, 0.022483916953206062, -128, -128, 127, torch.int8);  hardtanh__31 = None\n",
            "    dequantize_per_tensor_default_150 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_150, 0.022483916953206062, -128, -128, 127, torch.int8);  quantize_per_tensor_default_150 = None\n",
            "    _frozen_param47 = self._frozen_param47\n",
            "    dequantize_per_tensor_default_151 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param47, 0.008783008903265, 0, -127, 127, torch.int8);  _frozen_param47 = None\n",
            "    conv2d_47 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_150, dequantize_per_tensor_default_151);  dequantize_per_tensor_default_150 = dequantize_per_tensor_default_151 = None\n",
            "    quantize_per_tensor_default_152 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_47, 0.07830246537923813, 2, -128, 127, torch.int8);  conv2d_47 = None\n",
            "    dequantize_per_tensor_default_152 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_152, 0.07830246537923813, 2, -128, 127, torch.int8);  quantize_per_tensor_default_152 = None\n",
            "    _param_constant142 = self.features_16_conv_3_weight\n",
            "    _param_constant143 = self.features_16_conv_3_bias\n",
            "    _tensor_constant94 = self.features_16_conv_3_running_mean\n",
            "    _tensor_constant95 = self.features_16_conv_3_running_var\n",
            "    cudnn_batch_norm_47 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_152, _param_constant142, _param_constant143, _tensor_constant94, _tensor_constant95, False, 0.1, 1e-05);  dequantize_per_tensor_default_152 = _param_constant142 = _param_constant143 = _tensor_constant94 = _tensor_constant95 = None\n",
            "    getitem_188 = cudnn_batch_norm_47[0];  cudnn_batch_norm_47 = None\n",
            "    quantize_per_tensor_default_153 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_188, 0.18008503317832947, 1, -128, 127, torch.int8);  getitem_188 = None\n",
            "    dequantize_per_tensor_default_153 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_153, 0.18008503317832947, 1, -128, 127, torch.int8);  quantize_per_tensor_default_153 = None\n",
            "    add_9 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_191, dequantize_per_tensor_default_153);  dequantize_per_tensor_default_191 = dequantize_per_tensor_default_153 = None\n",
            "    quantize_per_tensor_default_154 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_9, 0.2277214527130127, 4, -128, 127, torch.int8);  add_9 = None\n",
            "    dequantize_per_tensor_default_154 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_154, 0.2277214527130127, 4, -128, 127, torch.int8);  quantize_per_tensor_default_154 = None\n",
            "    _frozen_param48 = self._frozen_param48\n",
            "    dequantize_per_tensor_default_155 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param48, 0.007324094884097576, 0, -127, 127, torch.int8);  _frozen_param48 = None\n",
            "    conv2d_48 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_154, dequantize_per_tensor_default_155);  dequantize_per_tensor_default_154 = dequantize_per_tensor_default_155 = None\n",
            "    quantize_per_tensor_default_156 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_48, 0.5065826177597046, -2, -128, 127, torch.int8);  conv2d_48 = None\n",
            "    dequantize_per_tensor_default_156 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_156, 0.5065826177597046, -2, -128, 127, torch.int8);  quantize_per_tensor_default_156 = None\n",
            "    _param_constant145 = self.features_17_conv_0_1_weight\n",
            "    _param_constant146 = self.features_17_conv_0_1_bias\n",
            "    _tensor_constant96 = self.features_17_conv_0_1_running_mean\n",
            "    _tensor_constant97 = self.features_17_conv_0_1_running_var\n",
            "    cudnn_batch_norm_48 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_156, _param_constant145, _param_constant146, _tensor_constant96, _tensor_constant97, False, 0.1, 1e-05);  dequantize_per_tensor_default_156 = _param_constant145 = _param_constant146 = _tensor_constant96 = _tensor_constant97 = None\n",
            "    getitem_192 = cudnn_batch_norm_48[0];  cudnn_batch_norm_48 = None\n",
            "    hardtanh__32 = torch.ops.aten.hardtanh_.default(getitem_192, 0.0, 6.0);  getitem_192 = None\n",
            "    quantize_per_tensor_default_157 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__32, 0.02336856722831726, -128, -128, 127, torch.int8);  hardtanh__32 = None\n",
            "    dequantize_per_tensor_default_157 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_157, 0.02336856722831726, -128, -128, 127, torch.int8);  quantize_per_tensor_default_157 = None\n",
            "    _frozen_param49 = self._frozen_param49\n",
            "    dequantize_per_tensor_default_158 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param49, 0.005901235621422529, 0, -127, 127, torch.int8);  _frozen_param49 = None\n",
            "    conv2d_49 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_157, dequantize_per_tensor_default_158, None, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_157 = dequantize_per_tensor_default_158 = None\n",
            "    quantize_per_tensor_default_159 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_49, 0.05428177863359451, 30, -128, 127, torch.int8);  conv2d_49 = None\n",
            "    dequantize_per_tensor_default_159 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_159, 0.05428177863359451, 30, -128, 127, torch.int8);  quantize_per_tensor_default_159 = None\n",
            "    _param_constant148 = self.features_17_conv_1_1_weight\n",
            "    _param_constant149 = self.features_17_conv_1_1_bias\n",
            "    _tensor_constant98 = self.features_17_conv_1_1_running_mean\n",
            "    _tensor_constant99 = self.features_17_conv_1_1_running_var\n",
            "    cudnn_batch_norm_49 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_159, _param_constant148, _param_constant149, _tensor_constant98, _tensor_constant99, False, 0.1, 1e-05);  dequantize_per_tensor_default_159 = _param_constant148 = _param_constant149 = _tensor_constant98 = _tensor_constant99 = None\n",
            "    getitem_196 = cudnn_batch_norm_49[0];  cudnn_batch_norm_49 = None\n",
            "    hardtanh__33 = torch.ops.aten.hardtanh_.default(getitem_196, 0.0, 6.0);  getitem_196 = None\n",
            "    quantize_per_tensor_default_160 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__33, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__33 = None\n",
            "    dequantize_per_tensor_default_160 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_160, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_160 = None\n",
            "    _frozen_param50 = self._frozen_param50\n",
            "    dequantize_per_tensor_default_161 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param50, 0.007264360319823027, 0, -127, 127, torch.int8);  _frozen_param50 = None\n",
            "    conv2d_50 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_160, dequantize_per_tensor_default_161);  dequantize_per_tensor_default_160 = dequantize_per_tensor_default_161 = None\n",
            "    quantize_per_tensor_default_162 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_50, 0.29328763484954834, 9, -128, 127, torch.int8);  conv2d_50 = None\n",
            "    dequantize_per_tensor_default_162 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_162, 0.29328763484954834, 9, -128, 127, torch.int8);  quantize_per_tensor_default_162 = None\n",
            "    _param_constant151 = self.features_17_conv_3_weight\n",
            "    _param_constant152 = self.features_17_conv_3_bias\n",
            "    _tensor_constant100 = self.features_17_conv_3_running_mean\n",
            "    _tensor_constant101 = self.features_17_conv_3_running_var\n",
            "    cudnn_batch_norm_50 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_162, _param_constant151, _param_constant152, _tensor_constant100, _tensor_constant101, False, 0.1, 1e-05);  dequantize_per_tensor_default_162 = _param_constant151 = _param_constant152 = _tensor_constant100 = _tensor_constant101 = None\n",
            "    getitem_200 = cudnn_batch_norm_50[0];  cudnn_batch_norm_50 = None\n",
            "    quantize_per_tensor_default_163 = torch.ops.quantized_decomposed.quantize_per_tensor.default(getitem_200, 0.1393735408782959, -15, -128, 127, torch.int8);  getitem_200 = None\n",
            "    dequantize_per_tensor_default_163 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_163, 0.1393735408782959, -15, -128, 127, torch.int8);  quantize_per_tensor_default_163 = None\n",
            "    _frozen_param51 = self._frozen_param51\n",
            "    dequantize_per_tensor_default_164 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param51, 0.00569280656054616, 0, -127, 127, torch.int8);  _frozen_param51 = None\n",
            "    conv2d_51 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_163, dequantize_per_tensor_default_164);  dequantize_per_tensor_default_163 = dequantize_per_tensor_default_164 = None\n",
            "    quantize_per_tensor_default_165 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_51, 0.8164896965026855, -4, -128, 127, torch.int8);  conv2d_51 = None\n",
            "    dequantize_per_tensor_default_165 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_165, 0.8164896965026855, -4, -128, 127, torch.int8);  quantize_per_tensor_default_165 = None\n",
            "    _param_constant154 = self.features_18_1_weight\n",
            "    _param_constant155 = self.features_18_1_bias\n",
            "    _tensor_constant102 = self.features_18_1_running_mean\n",
            "    _tensor_constant103 = self.features_18_1_running_var\n",
            "    cudnn_batch_norm_51 = torch.ops.aten.cudnn_batch_norm.default(dequantize_per_tensor_default_165, _param_constant154, _param_constant155, _tensor_constant102, _tensor_constant103, False, 0.1, 1e-05);  dequantize_per_tensor_default_165 = _param_constant154 = _param_constant155 = _tensor_constant102 = _tensor_constant103 = None\n",
            "    getitem_204 = cudnn_batch_norm_51[0];  cudnn_batch_norm_51 = None\n",
            "    hardtanh__34 = torch.ops.aten.hardtanh_.default(getitem_204, 0.0, 6.0);  getitem_204 = None\n",
            "    quantize_per_tensor_default_166 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__34, 0.023517923429608345, -128, -128, 127, torch.int8);  hardtanh__34 = None\n",
            "    dequantize_per_tensor_default_166 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_166, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_166 = None\n",
            "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_default_166, [1, 1]);  dequantize_per_tensor_default_166 = None\n",
            "    quantize_per_tensor_default_167 = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 0.023517923429608345, -128, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
            "    dequantize_per_tensor_default_167 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_167, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_167 = None\n",
            "    flatten = torch.ops.aten.flatten.using_ints(dequantize_per_tensor_default_167, 1);  dequantize_per_tensor_default_167 = None\n",
            "    quantize_per_tensor_default_168 = torch.ops.quantized_decomposed.quantize_per_tensor.default(flatten, 0.023517923429608345, -128, -128, 127, torch.int8);  flatten = None\n",
            "    dequantize_per_tensor_default_168 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_168, 0.023517923429608345, -128, -128, 127, torch.int8);  quantize_per_tensor_default_168 = None\n",
            "    dropout = torch.ops.aten.dropout.default(dequantize_per_tensor_default_168, 0.2, False);  dequantize_per_tensor_default_168 = None\n",
            "    quantize_per_tensor_default_169 = torch.ops.quantized_decomposed.quantize_per_tensor.default(dropout, 0.012622707523405552, -128, -128, 127, torch.int8);  dropout = None\n",
            "    dequantize_per_tensor_default_169 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_169, 0.012622707523405552, -128, -128, 127, torch.int8);  quantize_per_tensor_default_169 = None\n",
            "    _frozen_param52 = self._frozen_param52\n",
            "    dequantize_per_tensor_default_170 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param52, 0.0031057747546583414, 0, -127, 127, torch.int8);  _frozen_param52 = None\n",
            "    _param_constant157 = self.classifier_1_bias\n",
            "    linear = torch.ops.aten.linear.default(dequantize_per_tensor_default_169, dequantize_per_tensor_default_170, _param_constant157);  dequantize_per_tensor_default_169 = dequantize_per_tensor_default_170 = _param_constant157 = None\n",
            "    quantize_per_tensor_default_171 = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 0.20786839723587036, 10, -128, 127, torch.int8);  linear = None\n",
            "    dequantize_per_tensor_default_171 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_171, 0.20786839723587036, 10, -128, 127, torch.int8);  quantize_per_tensor_default_171 = None\n",
            "    return pytree.tree_unflatten([dequantize_per_tensor_default_171], self._out_spec)\n",
            "    \n",
            "# To see more debug info, please use `graph_module.print_readable()`\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "# device = torch.device('cpu')\n",
        "weight_path = '/content/drive/MyDrive/mobilenetv2_0.963.pth'\n",
        "model = torch.load(weight_path, map_location=torch.device('cpu'))\n",
        "model.to(device)\n",
        "print(next(model.parameters()).is_cuda)\n",
        "model.eval()\n",
        "example_inputs = (torch.randn(1, 3, 224, 224).to(device),)\n",
        "exported_model = capture_pre_autograd_graph(model, example_inputs)\n",
        "# Step 2. quantization\n",
        "from torch.ao.quantization.quantize_pt2e import (\n",
        "  prepare_pt2e,\n",
        "  convert_pt2e,\n",
        ")\n",
        "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
        "  XNNPACKQuantizer,\n",
        "  get_symmetric_quantization_config,\n",
        ")\n",
        "# from torch.ao.quantization.quantizer import (\n",
        "#   XNNPACKQuantizer,\n",
        "#   get_symmetric_quantization_config,\n",
        "# )\n",
        "# backend developer will write their own Quantizer and expose methods to allow\n",
        "# users to express how they\n",
        "# want the model to be quantized\n",
        "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())\n",
        "prepared_model = prepare_pt2e(exported_model, quantizer)\n",
        "# print(prepared_model.graph)\n",
        "# calibration omitted\n",
        "calibrate(prepared_model, test_loader, device)  # run calibration on sample data\n",
        "ptq_quantized_model = convert_pt2e(prepared_model)\n",
        "# print(ptq_quantized_model)\n",
        "# we have a model with aten ops doing integer computations when possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "G201Zn_kZiWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb18d1b0-e1cb-49c5-8210-336c28329759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modle has been export!\n"
          ]
        }
      ],
      "source": [
        "# Export the model and Save ExportedProgram\n",
        "pt2e_quantized_model_file_path =  \"./mobilenet_quantized.pt\"\n",
        "# capture the model to get an ExportedProgram\n",
        "example_inputs = (torch.randn(1, 3, 224, 224).to(device),)\n",
        "quantized_ep = torch.export.export(ptq_quantized_model, example_inputs)\n",
        "# use torch.export.save to save an ExportedProgram\n",
        "torch.export.save(quantized_ep, pt2e_quantized_model_file_path)\n",
        "print('Modle has been export!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mcQNgb08ZiWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0d084a57-516a-4dd2-c3f7-ed0fb43af576"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected input at *args[0].shape[0] to be equal to 1, but got 16",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e4c3e10d465c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_quantized_ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt2e_quantized_model_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_quantized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_quantized_ep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_quantized_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-10529c6db088>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m  \u001b[0;31m# type: ignore[method-assign]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: TRY200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcompatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_backward_compatible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m                 ):\n\u001b[1;32m   1560\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m                         \u001b[0margs_kwargs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0margs_kwargs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/external_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/_unlift.py\u001b[0m in \u001b[0;36m_check_input_constraints_pre_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     return _check_input_constraints_for_graph(\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"placeholder\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mflat_args_with_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py\u001b[0m in \u001b[0;36m_check_input_constraints_for_graph\u001b[0;34m(input_placeholders, flat_args_with_path, range_constraints)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0marg_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnode_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                         raise RuntimeError(\n\u001b[0m\u001b[1;32m    130\u001b[0m                             \u001b[0;34mf\"Expected input at {get_keystr(key_path)}.shape[{j}] to be equal to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34mf\"{node_dim}, but got {arg_dim}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected input at *args[0].shape[0] to be equal to 1, but got 16"
          ]
        }
      ],
      "source": [
        "loaded_quantized_ep = torch.export.load(pt2e_quantized_model_file_path)\n",
        "loaded_quantized_model = loaded_quantized_ep.module()\n",
        "acc = evaluate_model(loaded_quantized_model, test_loader, device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}